{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48862ac5",
   "metadata": {},
   "source": [
    "# üß†  Economic Context & Synthesis (EDA + Modeling)\n",
    "## üéØ M·ª•c ti√™u\n",
    "Ph√¢n t√≠ch c√°c **bi·∫øn kinh t·∫ø vƒ© m√¥** ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác **kh√°ch h√†ng c√≥ g·ª≠i ti·ªÅn (y)** hay kh√¥ng.  \n",
    "Sau ƒë√≥, x√¢y d·ª±ng c√°c m√¥ h√¨nh d·ª± ƒëo√°n v·ªõi **PySpark**, x·ª≠ l√Ω d·ªØ li·ªáu **m·∫•t c√¢n b·∫±ng** b·∫±ng **SMOTE**,  v√† ƒë√°nh gi√° m√¥ h√¨nh b·∫±ng **Cross-validation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39183a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë d√≤ng: 41188\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp.var.rate: double (nullable = true)\n",
      " |-- cons.price.idx: double (nullable = true)\n",
      " |-- cons.conf.idx: double (nullable = true)\n",
      " |-- euribor3m: double (nullable = true)\n",
      " |-- nr.employed: double (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "\n",
    "\n",
    "# T·∫°o SparkSession\n",
    "spark = SparkSession.builder.appName(\"Hao_Economic_Context_Synthesis\").getOrCreate()\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "data = spark.read.csv(\"../data/bank-additional/bank-additional-full.csv\", header=True, sep=';', inferSchema=True)\n",
    "print(\"S·ªë d√≤ng:\", data.count())\n",
    "data.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429271b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+\n",
      "|age|      job|marital|  education|default|housing|loan|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|emp.var.rate|cons.price.idx|cons.conf.idx|euribor3m|nr.employed|  y|\n",
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+\n",
      "| 56|housemaid|married|   basic.4y|     no|     no|  no|telephone|  may|        mon|     261|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no|\n",
      "| 57| services|married|high.school|unknown|     no|  no|telephone|  may|        mon|     149|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no|\n",
      "| 37| services|married|high.school|     no|    yes|  no|telephone|  may|        mon|     226|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no|\n",
      "| 40|   admin.|married|   basic.6y|     no|     no|  no|telephone|  may|        mon|     151|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no|\n",
      "| 56| services|married|high.school|     no|     no| yes|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|     5191.0| no|\n",
      "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d3da1",
   "metadata": {},
   "source": [
    "## üîç 2Ô∏è‚É£ EDA - Ph√¢n t√≠ch ·∫£nh h∆∞·ªüng c·ªßa c√°c bi·∫øn kinh t·∫ø vƒ© m√¥\n",
    "·ªû ƒë√¢y ta t·∫≠p trung v√†o 5 bi·∫øn vƒ© m√¥:\n",
    "- `emp.var.rate` ‚Äì t·ª∑ l·ªá bi·∫øn ƒë·ªông vi·ªác l√†m  \n",
    "- `cons.price.idx` ‚Äì ch·ªâ s·ªë gi√° ti√™u d√πng  \n",
    "- `cons.conf.idx` ‚Äì ch·ªâ s·ªë ni·ªÅm tin ng∆∞·ªùi ti√™u d√πng  \n",
    "- `euribor3m` ‚Äì l√£i su·∫•t EURIBOR 3 th√°ng  \n",
    "- `nr.employed` ‚Äì s·ªë ng∆∞·ªùi c√≥ vi·ªác l√†m  \n",
    "\n",
    "Ta s·∫Ω xem x√©t **ph√¢n ph·ªëi**, **t∆∞∆°ng quan** v√† **·∫£nh h∆∞·ªüng** c·ªßa ch√∫ng t·ªõi bi·∫øn m·ª•c ti√™u `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d356058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªïi t√™n c·ªôt ƒë·ªÉ tr√°nh l·ªói c√≥ d·∫•u ch·∫•m\n",
    "data = (data\n",
    "    .withColumnRenamed(\"emp.var.rate\", \"emp_var_rate\")\n",
    "    .withColumnRenamed(\"cons.price.idx\", \"cons_price_idx\")\n",
    "    .withColumnRenamed(\"cons.conf.idx\", \"cons_conf_idx\")\n",
    "    .withColumnRenamed(\"nr.employed\", \"nr_employed\")\n",
    ")\n",
    "\n",
    "macro_cols = [\"emp_var_rate\", \"cons_price_idx\", \"cons_conf_idx\", \"euribor3m\", \"nr_employed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b660bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1Ô∏è‚É£ Th·ªëng k√™ m√¥ t·∫£ c∆° b·∫£n ===\n",
      "+-------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "|summary|emp_var_rate       |cons_price_idx    |cons_conf_idx     |euribor3m         |nr_employed      |\n",
      "+-------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "|count  |41188              |41188             |41188             |41188             |41188            |\n",
      "|mean   |0.08188550063178392|93.57566436828918 |-40.50260027191787|3.6212908128585366|5167.035910944004|\n",
      "|stddev |1.57095974051703   |0.5788400489541355|4.628197856174595 |1.7344474048512557|72.25152766825924|\n",
      "|min    |-3.4               |92.201            |-50.8             |0.634             |4963.6           |\n",
      "|max    |1.4                |94.767            |-26.9             |5.045             |5228.1           |\n",
      "+-------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "\n",
      "=== 2Ô∏è‚É£ T·ª∑ l·ªá ph√¢n b·ªë bi·∫øn m·ª•c ti√™u y ===\n",
      "+---+-----+------------------+\n",
      "|  y|count|        percentage|\n",
      "+---+-----+------------------+\n",
      "| no|36548| 88.73458288821988|\n",
      "|yes| 4640|11.265417111780131|\n",
      "+---+-----+------------------+\n",
      "\n",
      "=== 3Ô∏è‚É£ Trung b√¨nh c√°c bi·∫øn vƒ© m√¥ theo t·ª´ng gi√° tr·ªã y ===\n",
      "+---+-------------------+------------------+-------------------+------------------+-----------------+\n",
      "|y  |avg_emp_var_rate   |avg_cons_price_idx|avg_cons_conf_idx  |avg_euribor3m     |avg_nr_employed  |\n",
      "+---+-------------------+------------------+-------------------+------------------+-----------------+\n",
      "|no |0.2488754514616543 |93.60375705922988 |-40.59309674947398 |3.8114911623072874|5176.166600086014|\n",
      "|yes|-1.2334482758620804|93.3543859913799  |-39.789784482759686|2.1231351293103327|5095.115991379181|\n",
      "+---+-------------------+------------------+-------------------+------------------+-----------------+\n",
      "\n",
      "=== 4Ô∏è‚É£ Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn vƒ© m√¥ ===\n",
      "+--------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|Feature       |emp_var_rate       |cons_price_idx     |cons_conf_idx       |euribor3m          |nr_employed        |\n",
      "+--------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|emp_var_rate  |1.0                |0.775334170834832  |0.19604126813197284 |0.9722446711516147 |0.9069701012560353 |\n",
      "|cons_price_idx|0.775334170834832  |1.0                |0.058986181748833216|0.688230107037495  |0.5220339770130168 |\n",
      "|cons_conf_idx |0.19604126813197287|0.05898618174883324|1.0                 |0.27768621966375506|0.10051343183753894|\n",
      "|euribor3m     |0.9722446711516147 |0.6882301070374951 |0.27768621966375506 |1.0                |0.9451544313982513 |\n",
      "|nr_employed   |0.9069701012560353 |0.5220339770130166 |0.10051343183753896 |0.9451544313982513 |1.0                |\n",
      "+--------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, mean, stddev, min as _min, max as _max, count, corr\n",
    "from pyspark.sql.types import FloatType\n",
    "# === ƒê·ªîI T√äN C·ªòT CHO H·ª¢P L·ªÜ (n·∫øu ch∆∞a l√†m) ===\n",
    "data = (data\n",
    "    .withColumnRenamed(\"emp.var.rate\", \"emp_var_rate\")\n",
    "    .withColumnRenamed(\"cons.price.idx\", \"cons_price_idx\")\n",
    "    .withColumnRenamed(\"cons.conf.idx\", \"cons_conf_idx\")\n",
    "    .withColumnRenamed(\"nr.employed\", \"nr_employed\")\n",
    ")\n",
    "\n",
    "# Danh s√°ch c√°c bi·∫øn vƒ© m√¥\n",
    "macro_cols = [\"emp_var_rate\", \"cons_price_idx\", \"cons_conf_idx\", \"euribor3m\", \"nr_employed\"]\n",
    "\n",
    "# --- 1Ô∏è‚É£ Th·ªëng k√™ m√¥ t·∫£ c∆° b·∫£n ---\n",
    "print(\"=== 1Ô∏è‚É£ Th·ªëng k√™ m√¥ t·∫£ c∆° b·∫£n ===\")\n",
    "data.select(macro_cols).describe().show(truncate=False)\n",
    "\n",
    "# --- 2Ô∏è‚É£ T·ª∑ l·ªá c√°c l·ªõp m·ª•c ti√™u (y) ---\n",
    "print(\"=== 2Ô∏è‚É£ T·ª∑ l·ªá ph√¢n b·ªë bi·∫øn m·ª•c ti√™u y ===\")\n",
    "total_count = data.count()\n",
    "data.groupBy(\"y\").agg(\n",
    "    count(\"*\").alias(\"count\")\n",
    ").withColumn(\n",
    "    \"percentage\", (col(\"count\") / total_count * 100)\n",
    ").show()\n",
    "\n",
    "# --- 3Ô∏è‚É£ Trung b√¨nh c√°c bi·∫øn vƒ© m√¥ theo t·ª´ng gi√° tr·ªã y ---\n",
    "print(\"=== 3Ô∏è‚É£ Trung b√¨nh c√°c bi·∫øn vƒ© m√¥ theo t·ª´ng gi√° tr·ªã y ===\")\n",
    "agg_exprs = [mean(c).alias(f\"avg_{c}\") for c in macro_cols]\n",
    "data.groupBy(\"y\").agg(*agg_exprs).show(truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76fafa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 4Ô∏è‚É£ Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn vƒ© m√¥ ===\n",
      "+--------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|Feature       |emp_var_rate       |cons_price_idx     |cons_conf_idx       |euribor3m          |nr_employed        |\n",
      "+--------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|emp_var_rate  |1.0                |0.775334170834832  |0.19604126813197284 |0.9722446711516147 |0.9069701012560353 |\n",
      "|cons_price_idx|0.775334170834832  |1.0                |0.058986181748833216|0.688230107037495  |0.5220339770130168 |\n",
      "|cons_conf_idx |0.19604126813197287|0.05898618174883324|1.0                 |0.27768621966375506|0.10051343183753894|\n",
      "|euribor3m     |0.9722446711516147 |0.6882301070374951 |0.27768621966375506 |1.0                |0.9451544313982513 |\n",
      "|nr_employed   |0.9069701012560353 |0.5220339770130166 |0.10051343183753896 |0.9451544313982513 |1.0                |\n",
      "+--------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4Ô∏è‚É£ Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn vƒ© m√¥ ---\n",
    "print(\"=== 4Ô∏è‚É£ Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn vƒ© m√¥ ===\")\n",
    "corr_matrix = []\n",
    "for c1 in macro_cols:\n",
    "    row = []\n",
    "    for c2 in macro_cols:\n",
    "        try:\n",
    "            val = data.select(corr(c1, c2).alias(\"corr\")).collect()[0][\"corr\"]\n",
    "        except Exception as e:\n",
    "            val = None\n",
    "        row.append(val)\n",
    "    corr_matrix.append((c1, *row))\n",
    "\n",
    "spark.createDataFrame(corr_matrix, [\"Feature\"] + macro_cols).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c17a89",
   "metadata": {},
   "source": [
    "- Nh√≥m bi·∫øn emp.var.rate, euribor3m, nr.employed c√≥ th·ªÉ ƒë∆∞·ª£c r√∫t g·ªçn ho·∫∑c ch·ªçn 1‚Äì2 ƒë·∫°i di·ªán.\n",
    "\n",
    "- C√°c bi·∫øn c√≥ t∆∞∆°ng quan √¢m v·ªõi y\n",
    "\n",
    "- Khi c√°c ch·ªâ s·ªë kinh t·∫ø n√†y tƒÉng (bi·ªÉu hi·ªán cho t√¨nh h√¨nh kinh t·∫ø t·ªët h∆°n), kh·∫£ nƒÉng kh√°ch h√†ng ƒë·ªìng √Ω g·ª≠i ti·ªÅn (y=1) l·∫°i gi·∫£m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877fcade",
   "metadata": {},
   "source": [
    "| Bi·∫øn vƒ© m√¥ (`feature`) | √ù nghƒ©a kinh t·∫ø                 | Xu h∆∞·ªõng khi bi·∫øn tƒÉng             | ·∫¢nh h∆∞·ªüng ƒë·∫øn kh·∫£ nƒÉng g·ª≠i ti·ªÅn (`y=1`) | M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng  | Ghi ch√∫                                                                    |\n",
    "| ---------------------- | ------------------------------- | ---------------------------------- | --------------------------------------- | ----------------- | -------------------------------------------------------------------------- |\n",
    "| **emp.var.rate**       | T·ª∑ l·ªá bi·∫øn ƒë·ªông vi·ªác l√†m        | Kinh t·∫ø ·ªïn ƒë·ªãnh h∆°n, vi·ªác l√†m tƒÉng | üîª Gi·∫£m kh·∫£ nƒÉng g·ª≠i ti·ªÅn               | **M·∫°nh (√¢m)**     | Khi t·ª∑ l·ªá vi·ªác l√†m cao, ng∆∞·ªùi d√¢n chi ti√™u nhi·ªÅu h∆°n, g·ª≠i ti·∫øt ki·ªám √≠t h∆°n |\n",
    "| **cons.price.idx**     | Ch·ªâ s·ªë gi√° ti√™u d√πng (l·∫°m ph√°t) | L·∫°m ph√°t tƒÉng                      | üîª Gi·∫£m nh·∫π kh·∫£ nƒÉng g·ª≠i ti·ªÅn           | **Y·∫øu (√¢m)**      | ·∫¢nh h∆∞·ªüng nh·ªè, th·ªÉ hi·ªán qua ch√™nh l·ªách nh·ªè gi·ªØa hai nh√≥m                   |\n",
    "| **cons.conf.idx**      | Ni·ªÅm tin ng∆∞·ªùi ti√™u d√πng        | T√¢m l√Ω ti√™u d√πng t√≠ch c·ª±c h∆°n      | ‚ö™ G·∫ßn nh∆∞ kh√¥ng ·∫£nh h∆∞·ªüng               | **R·∫•t y·∫øu**       | Ph√¢n b·ªë hai nh√≥m g·∫ßn nh∆∞ tr√πng nhau                                        |\n",
    "| **euribor3m**          | L√£i su·∫•t Euribor 3 th√°ng        | L√£i su·∫•t th·ªã tr∆∞·ªùng tƒÉng           | üîª Gi·∫£m m·∫°nh kh·∫£ nƒÉng g·ª≠i ti·ªÅn          | **M·∫°nh (√¢m)**     | Khi l√£i su·∫•t cao, kh√°ch h√†ng ∆∞u ti√™n ƒë·∫ßu t∆∞ h∆°n l√† g·ª≠i ti·∫øt ki·ªám           |\n",
    "| **nr.employed**        | S·ªë l∆∞·ª£ng ng∆∞·ªùi c√≥ vi·ªác l√†m      | Vi·ªác l√†m nhi·ªÅu h∆°n                 | üîª Gi·∫£m kh·∫£ nƒÉng g·ª≠i ti·ªÅn               | **Kh√° m·∫°nh (√¢m)** | Ph·∫£n √°nh m·ªëi li√™n h·ªá gi·ªØa th·ªã tr∆∞·ªùng lao ƒë·ªông v√† h√†nh vi ti·∫øt ki·ªám         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7856a8e5",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è 3Ô∏è‚É£ X·ª¨ L√ù M·∫§T C√ÇN B·∫∞NG D·ªÆ LI·ªÜU\n",
    "D·ªØ li·ªáu b·ªã **m·∫•t c√¢n b·∫±ng** khi t·ª∑ l·ªá kh√°ch h√†ng g·ª≠i ti·ªÅn (`y=1`) r·∫•t nh·ªè so v·ªõi `y=0`.  \n",
    "Ta d√πng **SMOTE (Synthetic Minority Oversampling Technique)** ƒë·ªÉ t·∫°o th√™m m·∫´u thi·ªÉu s·ªë nh√¢n t·∫°o.  \n",
    "- ∆Øu ƒëi·ªÉm: Gi·ªØ l·∫°i to√†n b·ªô d·ªØ li·ªáu g·ªëc, tr√°nh m·∫•t th√¥ng tin.  \n",
    "- Nh∆∞·ª£c ƒëi·ªÉm: C√≥ th·ªÉ t·∫°o nhi·ªÖu n·∫øu d·ªØ li·ªáu thi·ªÉu s·ªë kh√¥ng ph√¢n b·ªë t·ªët.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7881d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "| no|36548|\n",
      "|yes| 4640|\n",
      "+---+-----+\n",
      "\n",
      "D·ªØ li·ªáu sau c√¢n b·∫±ng:\n",
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "| no| 4617|\n",
      "|yes| 4640|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra t·ª∑ l·ªá nh√£n\n",
    "data.groupBy(\"y\").count().show()\n",
    "\n",
    "# C√¢n b·∫±ng d·ªØ li·ªáu (undersampling)\n",
    "yes_count = data.filter(col(\"y\") == \"yes\").count()\n",
    "no_df = data.filter(col(\"y\") == \"no\").sample(withReplacement=False, fraction=yes_count / data.filter(col(\"y\") == \"no\").count())\n",
    "yes_df = data.filter(col(\"y\") == \"yes\")\n",
    "\n",
    "data_balanced = no_df.union(yes_df)\n",
    "print(\"D·ªØ li·ªáu sau c√¢n b·∫±ng:\")\n",
    "data_balanced.groupBy(\"y\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b669d",
   "metadata": {},
   "source": [
    "## ü§ñ 4Ô∏è‚É£ X√ÇY D·ª∞NG M√î H√åNH C∆† B·∫¢N\n",
    "Ta b·∫Øt ƒë·∫ßu b·∫±ng c√°c **m√¥ h√¨nh c∆° b·∫£n** ƒë·ªÉ thi·∫øt l·∫≠p baseline:  \n",
    "1. **Logistic Regression** ‚Äì ƒë∆°n gi·∫£n, d·ªÖ gi·∫£i th√≠ch, d√πng l√†m baseline.  \n",
    "2. **Random Forest** ‚Äì b·∫Øt ƒë∆∞·ª£c quan h·ªá phi tuy·∫øn gi·ªØa c√°c bi·∫øn.  \n",
    "3. **Gradient Boosted Trees (GBT)** ‚Äì h·ªçc s√¢u h∆°n m·ªëi quan h·ªá vƒ© m√¥.  \n",
    "\n",
    "Vi·ªác ƒë√°nh gi√° d√πng **Cross-validation (3-fold)** v√† ch·ªâ s·ªë **Precision, Recall, F1-score**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "108e945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "\n",
    "# ƒê·ªïi t√™n ƒë·ªÉ tr√°nh l·ªói k√Ω t·ª± \".\"\n",
    "data_balanced = (data_balanced\n",
    "    .withColumnRenamed(\"emp.var.rate\", \"emp_var_rate\")\n",
    "    .withColumnRenamed(\"cons.price.idx\", \"cons_price_idx\")\n",
    "    .withColumnRenamed(\"cons.conf.idx\", \"cons_conf_idx\")\n",
    "    .withColumnRenamed(\"nr.employed\", \"nr_employed\")\n",
    ")\n",
    "\n",
    "# Vector features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"emp_var_rate\", \"cons_price_idx\", \"cons_conf_idx\", \"euribor3m\", \"nr_employed\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "final_data = assembler.transform(data_balanced).select(\"features\", \"y\")\n",
    "\n",
    "# Encode nh√£n (PySpark y√™u c·∫ßu d·∫°ng s·ªë)\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
    "final_data = indexer.fit(final_data).transform(final_data)\n",
    "\n",
    "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ff4de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== M√¥ h√¨nh: Logistic Regression ===\n",
      "Precision: 0.6939, Recall: 0.7173, F1: 0.7054\n",
      "\n",
      "=== M√¥ h√¨nh: Random Forest ===\n",
      "Precision: 0.6826, Recall: 0.8772, F1: 0.7677\n",
      "\n",
      "=== M√¥ h√¨nh: Gradient Boosted Trees ===\n",
      "Precision: 0.6867, Recall: 0.8227, F1: 0.7486\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=50),\n",
    "    \"Gradient Boosted Trees\": GBTClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "}\n",
    "\n",
    "def compute_metrics(df):\n",
    "    TP = df.filter((col(\"label\") == 1) & (col(\"prediction\") == 1)).count()\n",
    "    FP = df.filter((col(\"label\") == 0) & (col(\"prediction\") == 1)).count()\n",
    "    FN = df.filter((col(\"label\") == 1) & (col(\"prediction\") == 0)).count()\n",
    "    TN = df.filter((col(\"label\") == 0) & (col(\"prediction\") == 0)).count()\n",
    "    \n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== M√¥ h√¨nh: {name} ===\")\n",
    "    model_fit = model.fit(train_data)\n",
    "    pred = model_fit.transform(test_data)\n",
    "    \n",
    "    precision, recall, f1 = compute_metrics(pred)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    results.append((name, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa977d6d",
   "metadata": {},
   "source": [
    "## üìä 5Ô∏è‚É£ K·∫æT QU·∫¢ ƒê√ÅNH GI√Å\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c542bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ƒê·ªô quan tr·ªçng (Logistic Regression) ===\n",
      "emp_var_rate        : 0.352835\n",
      "cons_price_idx      : 0.367986\n",
      "cons_conf_idx       : 0.022573\n",
      "euribor3m           : 0.077800\n",
      "nr_employed         : 0.008766\n",
      "\n",
      "=== ƒê·ªô quan tr·ªçng (Random Forest) ===\n",
      "emp_var_rate        : 0.274023\n",
      "cons_price_idx      : 0.016082\n",
      "cons_conf_idx       : 0.064559\n",
      "euribor3m           : 0.119589\n",
      "nr_employed         : 0.525747\n",
      "\n",
      "=== ƒê·ªô quan tr·ªçng (Gradient Boosted Trees) ===\n",
      "emp_var_rate        : 0.126242\n",
      "cons_price_idx      : 0.086248\n",
      "cons_conf_idx       : 0.061508\n",
      "euribor3m           : 0.149200\n",
      "nr_employed         : 0.576801\n",
      "\n",
      "=== T·ªïng k·∫øt bi·∫øn quan tr·ªçng nh·∫•t ===\n",
      "M√¥ h√¨nh                        Bi·∫øn quan tr·ªçng nh·∫•t         Gi√° tr·ªã\n",
      "Logistic Regression            cons_price_idx              0.367986\n",
      "Random Forest                  nr_employed                 0.525747\n",
      "Gradient Boosted Trees         nr_employed                 0.576801\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\"emp_var_rate\", \"cons_price_idx\", \"cons_conf_idx\", \"euribor3m\", \"nr_employed\"]\n",
    "importance_summary = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    fitted = model.fit(train_data)\n",
    "    if hasattr(fitted, \"featureImportances\"):\n",
    "        importances = list(fitted.featureImportances)\n",
    "    elif hasattr(fitted, \"coefficients\"):\n",
    "        importances = [abs(x) for x in fitted.coefficients]\n",
    "    else:\n",
    "        importances = [0.0]*len(feature_cols)\n",
    "    \n",
    "    pairs = list(zip(feature_cols, importances))\n",
    "    print(f\"\\n=== ƒê·ªô quan tr·ªçng ({name}) ===\")\n",
    "    for col_name, imp in pairs:\n",
    "        print(f\"{col_name:<20}: {imp:.6f}\")\n",
    "    \n",
    "    max_idx = importances.index(max(importances, key=abs))\n",
    "    importance_summary.append((name, feature_cols[max_idx], importances[max_idx]))\n",
    "\n",
    "# T·ªïng k·∫øt\n",
    "print(\"\\n=== T·ªïng k·∫øt bi·∫øn quan tr·ªçng nh·∫•t ===\")\n",
    "print(f\"{'M√¥ h√¨nh':<30} {'Bi·∫øn quan tr·ªçng nh·∫•t':<25} {'Gi√° tr·ªã':>10}\")\n",
    "for row in importance_summary:\n",
    "    print(f\"{row[0]:<30} {row[1]:<25} {row[2]:>10.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
