{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bdc51d4",
   "metadata": {},
   "source": [
    "# Giới thiệu\n",
    "\n",
    "File notebook này thuộc nhóm phân tích **kênh và thời điểm liên hệ** trong chiến dịch marketing qua điện thoại của ngân hàng Bồ Đào Nha (Bank Marketing Dataset – Additional Full).\n",
    "\n",
    "**Mục tiêu phân tích:**\n",
    "- Khám phá **hiệu quả của từng kênh liên hệ** (`cellular` vs `telephone`) trong việc thuyết phục khách hàng gửi tiết kiệm kỳ hạn.  \n",
    "- Phân tích **thời điểm gọi** theo **tháng (`month`)** và **ngày trong tuần (`day_of_week`)** để xác định khi nào khách hàng có xu hướng phản hồi tích cực nhất.  \n",
    "- Đánh giá sự khác biệt về **tần suất và kết quả cuộc gọi** nhằm tìm ra **lịch gọi tối ưu**, giúp **giảm chi phí và tăng tỷ lệ chuyển đổi**.\n",
    "\n",
    "**Nguồn dữ liệu:**  \n",
    "Từ tập `bank-additional-full.csv` (41.188 quan sát) do UCI Machine Learning Repository cung cấp, mô tả chi tiết trong proposal của nhóm:contentReference[oaicite:1]{index=1}.  \n",
    "Các biến chính được sử dụng trong file này gồm:\n",
    "- `contact`: kênh liên hệ (cellular / telephone)  \n",
    "- `month`: tháng gọi  \n",
    "- `day_of_week`: ngày gọi  \n",
    "- `duration`, `campaign`, `pdays`, `previous`: đặc trưng hành vi cuộc gọi  \n",
    "- `y`: biến mục tiêu (khách hàng đồng ý “yes” hoặc từ chối “no”)\n",
    "\n",
    "**Kết quả mong đợi:**  \n",
    "Xác định được:\n",
    "- Kênh liên hệ hiệu quả nhất.  \n",
    "- Tháng và ngày có tỷ lệ “yes” cao nhất.  \n",
    "- Mối quan hệ giữa tần suất gọi và khả năng thành công.\n",
    "\n",
    "Phần sau sẽ tiến hành **làm sạch dữ liệu** và **khám phá phân bố các biến** trước khi phân tích sâu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a41122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init spark\n",
    "!pip install -q pyspark findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"analytics_data\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4d6a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giải phóng cache/persist cũ (train/val/test) nếu còn trong bộ nhớ\n",
    "for name in [\"train_ready\", \"val_ready\", \"test_ready\"]:\n",
    "    if name in globals():\n",
    "        df = globals()[name]\n",
    "        try:\n",
    "            df.unpersist()\n",
    "            print(f\"Đã unpersist {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Không thể unpersist {name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d395c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biến hiện có trong globals():\n",
      "[]\n",
      "\n",
      "Cache hiện có trong Spark:\n",
      "train_ready chưa tồn tại trong Spark catalog.\n",
      "val_ready chưa tồn tại trong Spark catalog.\n",
      "test_ready chưa tồn tại trong Spark catalog.\n",
      "\n",
      "Đã dọn toàn bộ cache Spark.\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra các biến DataFrame đã tồn tại trong môi trường Python (global scope)\n",
    "print(\"Biến hiện có trong globals():\")\n",
    "print([v for v in [\"train_ready\", \"val_ready\", \"test_ready\"] if v in globals()])\n",
    "\n",
    "# Kiểm tra cache trong Spark (cấp cluster)\n",
    "print(\"\\nCache hiện có trong Spark:\")\n",
    "for name in [\"train_ready\", \"val_ready\", \"test_ready\"]:\n",
    "    try:\n",
    "        if spark.catalog.isCached(name):\n",
    "            print(f\"{name} đang được cache trong Spark.\")\n",
    "        else:\n",
    "            print(f\"{name} chưa được cache trong Spark.\")\n",
    "    except:\n",
    "        print(f\"{name} chưa tồn tại trong Spark catalog.\")\n",
    "\n",
    "# Dọn toàn bộ cache Spark\n",
    "spark.catalog.clearCache()\n",
    "print(\"\\nĐã dọn toàn bộ cache Spark.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920d805",
   "metadata": {},
   "source": [
    "### 0. Làm sạch dữ liệu và kiểm tra phân bố\n",
    "\n",
    "Bộ dữ liệu “Bank Marketing – Additional Full” chứa thông tin 41.188 khách hàng được gọi điện trong các chiến dịch marketing của một ngân hàng Bồ Đào Nha (2008–2010).  \n",
    "Mục tiêu là dự đoán khả năng **khách hàng đồng ý gửi tiết kiệm kỳ hạn (y = yes/no)** dựa trên thông tin liên hệ, chiến dịch và bối cảnh.\n",
    "\n",
    "Ở phần này, ta sẽ:\n",
    "- Kiểm tra schema, số lượng dòng, và giá trị null.  \n",
    "- Thống kê phân bố sơ bộ của các biến phân loại và biến số.  \n",
    "- Phát hiện outlier, dữ liệu mất cân bằng, và chuẩn bị cho EDA chi tiết ở các phần sau.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6cb9f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------+--------+--------+-----+--------+---+\n",
      "|contact  |month|day_of_week|duration|campaign|pdays|previous|y  |\n",
      "+---------+-----+-----------+--------+--------+-----+--------+---+\n",
      "|telephone|may  |mon        |261     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |149     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |226     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |151     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |307     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |198     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |139     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |217     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |380     |1       |999  |0       |no |\n",
      "|telephone|may  |mon        |50      |1       |999  |0       |no |\n",
      "+---------+-----+-----------+--------+--------+-----+--------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/bank-additional/bank-additional-full.csv\"\n",
    "raw_df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferschema\", True)\n",
    "    .option(\"sep\", \";\")\n",
    "    .csv(path)\n",
    ")\n",
    "\n",
    "cols = ['contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous']\n",
    "target_col = 'y'\n",
    "df = raw_df.select(*(cols + [target_col]))\n",
    "\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb0c42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema df: \n",
      "root\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n",
      "__________________________________________\n",
      "\n",
      " So dong df: \n",
      "41188\n",
      "__________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"schema df: \")\n",
    "df.printSchema()\n",
    "print(\"__________________________________________\")\n",
    "\n",
    "print(\"\\n So dong df: \")\n",
    "print(df.count())\n",
    "print(\"__________________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8bca9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking missing values: \n",
      "contact              null = 0\n",
      "month                null = 0\n",
      "day_of_week          null = 0\n",
      "duration             null = 0\n",
      "campaign             null = 0\n",
      "pdays                null = 0\n",
      "previous             null = 0\n",
      "y                    null = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking missing values: \")\n",
    "total = df.count()\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "for c in df.columns:\n",
    "    miss = df.filter(F.col(c).isNull()).count()\n",
    "    print(f\"{c:20s} null = {miss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a38e3",
   "metadata": {},
   "source": [
    "### * Tỷ lệ phân bố giữa các biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5f67e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---------+\n",
      "|  contact|count|ratio (%)|\n",
      "+---------+-----+---------+\n",
      "| cellular|26144|    63.47|\n",
      "|telephone|15044|    36.53|\n",
      "+---------+-----+---------+\n",
      "\n",
      "+-----+-----+---------+\n",
      "|month|count|ratio (%)|\n",
      "+-----+-----+---------+\n",
      "|  may|13769|    33.43|\n",
      "|  jul| 7174|    17.42|\n",
      "|  aug| 6178|     15.0|\n",
      "|  jun| 5318|    12.91|\n",
      "|  nov| 4101|     9.96|\n",
      "|  apr| 2632|     6.39|\n",
      "|  oct|  718|     1.74|\n",
      "|  sep|  570|     1.38|\n",
      "|  mar|  546|     1.33|\n",
      "|  dec|  182|     0.44|\n",
      "+-----+-----+---------+\n",
      "\n",
      "+-----------+-----+---------+\n",
      "|day_of_week|count|ratio (%)|\n",
      "+-----------+-----+---------+\n",
      "|        thu| 8623|    20.94|\n",
      "|        mon| 8514|    20.67|\n",
      "|        wed| 8134|    19.75|\n",
      "|        tue| 8090|    19.64|\n",
      "|        fri| 7827|     19.0|\n",
      "+-----------+-----+---------+\n",
      "\n",
      "+---+-----+---------+\n",
      "|  y|count|ratio (%)|\n",
      "+---+-----+---------+\n",
      "| no|36548|    88.73|\n",
      "|yes| 4640|    11.27|\n",
      "+---+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat_cols = ['contact', 'month', 'day_of_week', 'y']\n",
    "for c in cat_cols:\n",
    "    fre_val = df.groupBy(c).count().orderBy('count', ascending = False)\n",
    " \n",
    "    total = df.count()\n",
    "    col_expr = ((F.col('count') / total) * 100).cast(\"double\")\n",
    "    fre_val.withColumn(\"ratio (%)\", F.round(col_expr, 2)).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111de2d5",
   "metadata": {},
   "source": [
    "#### Nhận xét phân tích tần suất các biến phân loại\n",
    "\n",
    "#####  `contact` — Kênh liên hệ\n",
    "Tỷ lệ **cellular (63.5%)** cao hơn **telephone (36.5%)**.  \n",
    "Điều này phản ánh đúng thực tế giai đoạn 2008–2010, khi ngân hàng chuyển dần sang gọi qua **di động** để tiếp cận khách hàng nhanh hơn.  \n",
    "\n",
    "Khi phân tích hiệu quả chiến dịch, cần kiểm tra xem **tỷ lệ “yes”** giữa hai kênh này có khác biệt đáng kể không.  \n",
    "Nếu di động có tỷ lệ thành công cao hơn, đó là tín hiệu cho việc **ưu tiên kênh liên hệ** này trong các chiến dịch sau.\n",
    "\n",
    "\n",
    "\n",
    "##### `month` — Tháng gọi\n",
    "Các tháng có nhiều cuộc gọi nhất:\n",
    "- **May (33%)**\n",
    "- **July (17%)**\n",
    "- **August (15%)**\n",
    "- **June (13%)**\n",
    "\n",
    "→ Chiếm hơn **75% tổng số cuộc gọi**.  \n",
    "Có thể đây là **chiến dịch mùa hè**, khi ngân hàng đẩy mạnh huy động vốn hoặc tung sản phẩm mới.\n",
    "\n",
    "Các tháng khác (Oct, Sep, Mar, Dec) có tỷ lệ rất nhỏ → thường là **off-campaign** hoặc **chiến dịch thử nghiệm**.  \n",
    "Nên kiểm tra thêm xem **tỷ lệ “yes” có biến động theo mùa** không; ví dụ: tháng May gọi nhiều nhưng hiệu quả có thể không cao.\n",
    "\n",
    "\n",
    "\n",
    "#####  `day_of_week` — Ngày gọi\n",
    "Phân bố **khá đồng đều (khoảng 19–21%)** mỗi ngày.  \n",
    "Điều này cho thấy ngân hàng triển khai chiến dịch đều trong tuần, **không tập trung riêng vào đầu hoặc cuối tuần**.\n",
    "\n",
    "Đây là đặc điểm tốt, giúp **loại bỏ bias theo ngày** khi huấn luyện mô hình.  \n",
    "Tuy nhiên, vẫn nên xem thử **thứ Sáu** có tỷ lệ “yes” cao hơn không — vì khách hàng cuối tuần có thể tâm lý thoải mái hơn.\n",
    "\n",
    "\n",
    "\n",
    "#####  `y` — Biến mục tiêu (kết quả)\n",
    "Dữ liệu **rất mất cân bằng**:  \n",
    "- **Yes:** 11.3%  \n",
    "- **No:** 88.7%\n",
    "\n",
    "Đây là đặc trưng nổi tiếng của **Bank Marketing Dataset**.  \n",
    "Hệ quả: nếu huấn luyện mô hình mà **không xử lý imbalance**, mô hình sẽ thiên về dự đoán “no”.\n",
    "\n",
    "→ Ở bước mô hình hóa, cần **cân bằng lớp** bằng:\n",
    "- `class_weighting`\n",
    "- `SMOTE`\n",
    "- hoặc `resampling`\n",
    "\n",
    "để đảm bảo mô hình học được tín hiệu thực sự của nhóm “yes”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d593f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-------------------+\n",
      "|summary|          duration|         campaign|            pdays|           previous|\n",
      "+-------+------------------+-----------------+-----------------+-------------------+\n",
      "|  count|             41188|            41188|            41188|              41188|\n",
      "|   mean| 258.2850101971448|2.567592502670681|962.4754540157328|0.17296299893172767|\n",
      "| stddev|259.27924883646455|2.770013542902331|186.9109073447414|0.49490107983928927|\n",
      "|    min|                 0|                1|                0|                  0|\n",
      "|    max|              4918|               56|              999|                  7|\n",
      "+-------+------------------+-----------------+-----------------+-------------------+\n",
      "\n",
      "[[102.0, 177.0, 312.0, 526.0, 702.0, 4918.0], [1.0, 2.0, 3.0, 5.0, 6.0, 56.0], [999.0, 999.0, 999.0, 999.0, 999.0, 999.0], [0.0, 0.0, 0.0, 1.0, 1.0, 7.0]] \n",
      "\n",
      "Percentile cua duration: \n",
      "{'25%': 102.0, '50%': 177.0, '75%': 312.0, '90%': 526.0, '95%': 702.0, '99%': 4918.0} \n",
      "\n",
      "Percentile cua campaign: \n",
      "{'25%': 1.0, '50%': 2.0, '75%': 3.0, '90%': 5.0, '95%': 6.0, '99%': 56.0} \n",
      "\n",
      "Percentile cua pdays: \n",
      "{'25%': 999.0, '50%': 999.0, '75%': 999.0, '90%': 999.0, '95%': 999.0, '99%': 999.0} \n",
      "\n",
      "Percentile cua previous: \n",
      "{'25%': 0.0, '50%': 0.0, '75%': 0.0, '90%': 1.0, '95%': 1.0, '99%': 7.0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Kiem tra tan suat phan bo cua cac bien so\n",
    "num_cols = ['duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "df.select(num_cols).describe().show()\n",
    "\n",
    "percentiles = df.approxQuantile(num_cols, [0.25, 0.5, 0.75, 0.9, 0.95, 0.99], 0.01)\n",
    "print(percentiles, \"\\n\")\n",
    "\n",
    "\n",
    "for i, c in enumerate(num_cols):\n",
    "    res = dict(zip([\"25%\", \"50%\", \"75%\", \"90%\", \"95%\", \"99%\"], percentiles[i]))\n",
    "    print(f\"Percentile cua {c}: \")\n",
    "    print(res, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5043bfe",
   "metadata": {},
   "source": [
    "#### Nhận xét phân tích các biến số\n",
    "\n",
    "##### a. `duration` — Thời lượng cuộc gọi\n",
    "- Trung bình khoảng **258 giây**, độ lệch chuẩn gần bằng trung bình → **phân bố rất lệch phải (right-skewed)**.  \n",
    "- **75%** cuộc gọi kéo dài ≤ **312 giây**, nhưng **1% trên cùng** lên tới gần **5000 giây (~82 phút)** → có **outlier mạnh**.  \n",
    "- Điều này hợp lý, vì đa số khách hàng từ chối sớm; còn các cuộc gọi dài thường đến từ khách hàng có hứng thú hoặc nhân viên thuyết phục lâu.  \n",
    "- Tuy nhiên, như đã nói ở phần trước, `duration` **không nên dùng để dự đoán trực tiếp**, vì đây là **kết quả sau khi gọi**, không phải thông tin biết trước.  \n",
    "  → Dùng trong **EDA (phân tích khám phá dữ liệu)** để hiểu hành vi khách hàng là hợp lý.\n",
    "\n",
    "\n",
    "\n",
    "##### b. `campaign` — Số lần liên hệ trong chiến dịch hiện tại\n",
    "- **Trung vị = 2**, **75% ≤ 3**, nhưng **1% cao nhất** lên tới **56 lần** → có những khách hàng bị gọi **hơn 50 lần (!)**  \n",
    "- Đây là **outlier rõ ràng**, nhưng lại chứa **thông tin hành vi**: chiến dịch đã cố gắng “đuổi theo” khách hàng đó.  \n",
    "- Khi mô hình hóa, nên:\n",
    "  - **Giới hạn (clip)** giá trị tối đa ở một ngưỡng hợp lý (ví dụ 10), hoặc  \n",
    "  - **Log-transform** để giảm ảnh hưởng của các giá trị cực lớn.\n",
    "\n",
    "\n",
    "\n",
    "##### c. `pdays` — Số ngày từ lần liên hệ trước\n",
    "- Tất cả các percentile đều = **999**, cho thấy **phần lớn khách hàng chưa từng được liên hệ trước đây**.  \n",
    "- Theo mô tả dữ liệu, **999 nghĩa là “no previous contact”**.  \n",
    "- Biến này ít thông tin trực tiếp, nên khi xử lý có thể:\n",
    "  - Tạo biến nhị phân mới: `has_contact_before = (pdays != 999)`, hoặc  \n",
    "  - Giữ nguyên 999 và để mô hình tự học (tùy thuật toán).\n",
    "\n",
    "\n",
    "\n",
    "##### d. `previous` — Số lần liên hệ trước chiến dịch hiện tại\n",
    "- **75% khách hàng chưa từng được liên hệ (0)**, **95% ≤ 1**, chỉ vài người đến **7 lần**.  \n",
    "- Nghĩa là **đa số là khách hàng mới**.  \n",
    "- Biến này có **phân bố rất lệch (one-sided)**, nên khi đưa vào mô hình cần:\n",
    "  - **Chuẩn hóa (scaling)** hoặc  \n",
    "  - **Binning (phân nhóm)** để mô hình dễ học và ổn định hơn.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae925b0d",
   "metadata": {},
   "source": [
    "### 1. Insight về hành vi liên hệ (kênh – thời điểm – kết quả):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd448e",
   "metadata": {},
   "source": [
    "#### 1.1 Về kênh liên hệ \n",
    "→ Mục tiêu: tìm hiểu kênh và thời điểm nào hiệu quả nhất.\n",
    "**Câu hỏi khai thác:**\n",
    "\n",
    "- Kênh cellular có giúp tăng tỷ lệ phản hồi tích cực không?\n",
    "\n",
    "- Liệu telephone có thể bị loại bỏ hoặc giảm tần suất để tiết kiệm chi phí?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e0551a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ty le khách hang say yes trong cellular la:14.74% tren tong so 26144 \n",
      "\n",
      "ty le  khach hang say yes khi su dung telephone la:5.23% tren tong so 15044 \n"
     ]
    }
   ],
   "source": [
    "#Tỷ lệ khách hàng \"yes\" của từng kênh\n",
    "cellular_total = df.filter(df['contact'] == 'cellular').count()\n",
    "yes_cellular = df.filter((df['contact'] == 'cellular') & (df['y'] == 'yes')).count()\n",
    "cellular_ratio = round(yes_cellular / cellular_total * 100, 2)\n",
    "print(f\"Ty le khách hang say yes trong cellular la:{cellular_ratio}% tren tong so {cellular_total} \\n\")\n",
    "\n",
    "\n",
    "\n",
    "telephone_total = df.filter(df['contact'] == 'telephone').count()\n",
    "yes_telephone = df.filter((df['contact'] == 'telephone') & (df['y'] == 'yes')).count()\n",
    "telephone_ratio = round(yes_telephone / telephone_total * 100, 2)\n",
    "print(f\"ty le  khach hang say yes khi su dung telephone la:{telephone_ratio}% tren tong so {telephone_total} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1635e7a6",
   "metadata": {},
   "source": [
    "Phân tích cho thấy **kênh di động (cellular)** có tỷ lệ khách hàng đồng ý gửi tiết kiệm **cao gấp gần 3 lần** so với **điện thoại bàn (telephone)**.\n",
    "\n",
    "- **Cellular:** 14.74% khách hàng đồng ý trên tổng **26,144 cuộc gọi**.  \n",
    "- **Telephone:** 5.23% khách hàng đồng ý trên tổng **15,044 cuộc gọi**.\n",
    "\n",
    "👉 **Kết luận:**  \n",
    "Kênh **di động** cho thấy **hiệu quả vượt trội**, có thể do khách hàng **dễ tiếp cận hơn** và **phản hồi nhanh hơn**.  \n",
    "**Đề xuất:** Ngân hàng nên **ưu tiên ngân sách và nhân sự cho kênh di động**, đồng thời **giảm tần suất gọi qua điện thoại bàn** để **tối ưu chi phí và nâng cao tỷ lệ chuyển đổi**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9034246",
   "metadata": {},
   "source": [
    "#### 1.2 Về tháng gọi (month)\n",
    "\n",
    "→ **Mục tiêu:** kiểm tra xem yếu tố **mùa vụ** có ảnh hưởng đến tỷ lệ khách hàng đồng ý (“yes”) hay không.\n",
    "\n",
    "**Câu hỏi khai thác:**\n",
    "\n",
    "- Có phải **tháng May** tuy có nhiều cuộc gọi nhưng **tỷ lệ thành công lại thấp**?\n",
    "\n",
    "- **Tháng March** hoặc **September** có thể là “**thời điểm vàng**” – ít cuộc gọi nhưng **hiệu quả cao hơn**?\n",
    "\n",
    "- Có **mối quan hệ nào giữa số lượng cuộc gọi và tỷ lệ thành công** (gọi nhiều chưa chắc tốt hơn)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "873f7e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-------------+\n",
      "|month|total|yes_count|yes_ratio (%)|\n",
      "+-----+-----+---------+-------------+\n",
      "|  may|13769|      886|         6.43|\n",
      "|  jul| 7174|      649|         9.05|\n",
      "|  nov| 4101|      416|        10.14|\n",
      "|  jun| 5318|      559|        10.51|\n",
      "|  aug| 6178|      655|         10.6|\n",
      "|  apr| 2632|      539|        20.48|\n",
      "|  oct|  718|      315|        43.87|\n",
      "|  sep|  570|      256|        44.91|\n",
      "|  dec|  182|       89|         48.9|\n",
      "|  mar|  546|      276|        50.55|\n",
      "+-----+-----+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month_df = (\n",
    "    df.groupBy('month')\n",
    "      .agg(\n",
    "          F.count('*').alias('total'),\n",
    "          F.sum((F.col('y') == 'yes').cast('int')).alias('yes_count')\n",
    "      )\n",
    "      .withColumn('yes_ratio (%)', F.round(F.col('yes_count')/F.col('total')* 100, 2))\n",
    "      .orderBy('yes_ratio (%)')\n",
    ")\n",
    "month_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e2eda",
   "metadata": {},
   "source": [
    "Phân tích cho thấy các chiến dịch được triển khai mạnh nhất vào **tháng May, July và August**, nhưng **tỷ lệ thành công lại khá thấp**.  \n",
    "Ngược lại, những tháng có **ít cuộc gọi** như **March, September, October và December** lại có tỷ lệ “yes” **rất cao** — thậm chí **gấp 5–8 lần so với tháng May**.\n",
    "\n",
    "- **Tháng May:** 6.43% khách hàng đồng ý trên tổng **13,769 cuộc gọi**.  \n",
    "- **Tháng August:** 10.6% khách hàng đồng ý trên tổng **6,178 cuộc gọi**.  \n",
    "- **Tháng April:** 20.48% khách hàng đồng ý trên tổng **2,632 cuộc gọi**.  \n",
    "- **Tháng March:** 50.55% khách hàng đồng ý trên tổng **546 cuộc gọi**.\n",
    "\n",
    "👉 **Kết luận:**  \n",
    "Hiệu quả chiến dịch có **tính mùa vụ rõ rệt**.  \n",
    "Những tháng ngân hàng **gọi nhiều (đặc biệt là May, July)** lại có **tỷ lệ phản hồi thấp**,  \n",
    "trong khi các tháng **ít gọi (March, September, October, December)** mang lại **tỷ lệ thành công vượt trội**.\n",
    "\n",
    "**Đề xuất:**  \n",
    "Ngân hàng nên **tái phân bổ lịch gọi**, **tăng cường chiến dịch** vào các tháng có hiệu quả cao,  \n",
    "đồng thời **giảm tần suất** ở các tháng thấp hiệu quả như **May–July** để **nâng cao hiệu suất tổng thể**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f80d1f8",
   "metadata": {},
   "source": [
    "#### 1.3 Về ngày trong tuần (day_of_week)\n",
    "\n",
    "→ **Mục tiêu:** xác định **ngày nào trong tuần** mang lại **tỷ lệ khách hàng đồng ý cao nhất**,  \n",
    "từ đó hỗ trợ ngân hàng **lên lịch gọi tối ưu** cho đội ngũ tư vấn.\n",
    "\n",
    "**Câu hỏi khai thác:**\n",
    "\n",
    "- Liệu khách hàng có xu hướng **đồng ý nhiều hơn vào cuối tuần** (thứ Năm, thứ Sáu) khi **tâm lý thoải mái hơn**?\n",
    "\n",
    "- Có **sự khác biệt rõ** giữa **đầu tuần** và **cuối tuần** hay không?\n",
    "\n",
    "- Ngân hàng có thể **ưu tiên gọi vào các ngày “hiệu quả” hơn** để **tăng tỷ lệ chuyển đổi**?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985364d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+---------+------------+\n",
      "|day_of_week|total|yes_count|yes_ratio(%)|\n",
      "+-----------+-----+---------+------------+\n",
      "|        thu| 8623|     1045|       12.12|\n",
      "|        tue| 8090|      953|       11.78|\n",
      "|        wed| 8134|      949|       11.67|\n",
      "|        fri| 7827|      846|       10.81|\n",
      "|        mon| 8514|      847|        9.95|\n",
      "+-----------+-----+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dayOfWeek_df = (\n",
    "    df.groupBy('day_of_week')\n",
    "      .agg(\n",
    "         F.count('*').alias('total'),\n",
    "         F.sum((F.col('y') == 'yes').cast('int')).alias('yes_count')\n",
    "      )\n",
    "      .withColumn('yes_ratio(%)', F.round((F.col('yes_count')/F.col('total') * 100), 2))\n",
    "      .orderBy('yes_ratio(%)',ascending = False)\n",
    ")\n",
    "dayOfWeek_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa71732",
   "metadata": {},
   "source": [
    "Phân tích cho thấy **tỷ lệ khách hàng “say yes” cao nhất** rơi vào **thứ Năm (12.12%)**,  \n",
    "tiếp theo là **thứ Ba (11.78%)** và **thứ Tư (11.67%)**.  \n",
    "Trong khi đó, **thứ Hai có tỷ lệ thấp nhất (9.95%)** — tức là **đầu tuần khách hàng ít phản hồi tích cực hơn**.\n",
    "\n",
    "- **Thứ Năm:** 12.12% khách hàng đồng ý trên tổng **8,623 cuộc gọi**.  \n",
    "- **Thứ Ba:** 11.78% khách hàng đồng ý trên tổng **8,090 cuộc gọi**.  \n",
    "- **Thứ Hai:** 9.95% khách hàng đồng ý trên tổng **8,514 cuộc gọi**.\n",
    "\n",
    "👉 **Kết luận:**  \n",
    "Tỷ lệ phản hồi tích cực có **xu hướng tăng dần về giữa và cuối tuần**, đạt **đỉnh vào thứ Năm**.  \n",
    "Điều này gợi ý rằng **thời điểm giữa – cuối tuần** là **“khung giờ vàng” để triển khai cuộc gọi**,  \n",
    "khi khách hàng có **tâm lý thoải mái** và **sẵn sàng tương tác hơn**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a249a05",
   "metadata": {},
   "source": [
    "### 2: “Tần suất & lịch sử liên hệ.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1bf21",
   "metadata": {},
   "source": [
    "#### 2.1. Tần suất gọi trong chiến dịch hiện tại – campaign\n",
    "→ **Mục tiêu:** xem việc **gọi nhiều hơn trong cùng một chiến dịch** có làm **tăng khả năng khách hàng “yes”** hay không.\n",
    "\n",
    "**Cần phân tích:**\n",
    "\n",
    "- So sánh **trung bình số lần gọi (campaign)** giữa nhóm **“yes”** và **“no”**.  \n",
    "- Tính **tỷ lệ “yes” theo nhóm tần suất gọi**, ví dụ: **1–2**, **3–5**, **>5 lần**.\n",
    "\n",
    "**Câu hỏi khai thác:**\n",
    "\n",
    "- Liệu **gọi quá nhiều có phản tác dụng** không?  \n",
    "- Có tồn tại **ngưỡng “số lần gọi tối ưu”** nào cho chiến dịch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8721039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|  y|avg_calls|\n",
      "+---+---------+\n",
      "| no|     2.63|\n",
      "|yes|     2.05|\n",
      "+---+---------+\n",
      "\n",
      "+--------------+-----+---------+-------------+\n",
      "|campaign_group|total|yes_count|yes_ratio (%)|\n",
      "+--------------+-----+---------+-------------+\n",
      "|          high| 3385|      186|         5.49|\n",
      "|           low|28212|     3511|        12.45|\n",
      "|        medium| 9591|      943|         9.83|\n",
      "+--------------+-----+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trung bình số lần gọi giữa hai nhóm yes / no\n",
    "avg_calls = df.groupBy(\"y\").agg(F.round(F.avg(\"campaign\"), 2).alias(\"avg_calls\"))\n",
    "avg_calls.show()\n",
    "\n",
    "# Phân nhóm tần suất gọi: ít - trung bình - nhiều\n",
    "campaign_gr = (\n",
    "    df.withColumn(\n",
    "        'campaign_group',\n",
    "        F.when(F.col('campaign') <= 2, \"low\")\n",
    "        .when(F.col('campaign') <= 5, \"medium\")\n",
    "        .otherwise(\"high\")\n",
    "    )\n",
    "    .groupBy('campaign_group')\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total\"),\n",
    "        F.sum((F.col(\"y\") == \"yes\").cast(\"int\")).alias(\"yes_count\")\n",
    "    )\n",
    "    .withColumn(\"yes_ratio (%)\", F.round(F.col(\"yes_count\") / F.col(\"total\") * 100, 2))\n",
    "    .orderBy(\"campaign_group\")\n",
    ")\n",
    "\n",
    "campaign_gr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4a6df",
   "metadata": {},
   "source": [
    "Phân tích cho thấy những khách hàng **đồng ý gửi tiết kiệm (“yes”)** chỉ được gọi trung bình **2.05 lần**,  \n",
    "trong khi nhóm **từ chối (“no”)** được gọi trung bình **2.63 lần**.  \n",
    "Điều này gợi ý rằng **gọi quá nhiều lần không giúp tăng hiệu quả**, thậm chí **có xu hướng phản tác dụng**.\n",
    "\n",
    "**Phân nhóm tần suất gọi:**\n",
    "\n",
    "- **Nhóm ít (≤ 2 lần):** tỷ lệ thành công **12.45%** trên tổng **28,212 cuộc gọi**.  \n",
    "- **Nhóm trung bình (3–5 lần):** tỷ lệ thành công **9.83%** trên tổng **9,591 cuộc gọi**.  \n",
    "- **Nhóm cao (>5 lần):** tỷ lệ thành công chỉ **5.49%** trên tổng **3,385 cuộc gọi**.\n",
    "\n",
    "👉 **Kết luận:**  \n",
    "Tần suất gọi cao **không làm tăng tỷ lệ đồng ý**; ngược lại, **càng gọi nhiều khách hàng càng ít phản hồi tích cực**.  \n",
    "Điều này cho thấy **nhiều khách hàng có thể cảm thấy phiền** khi bị liên hệ lặp lại trong cùng chiến dịch.\n",
    "\n",
    "**Đề xuất:**  \n",
    "Ngân hàng nên **giới hạn số lần gọi tối đa ở mức 2–3 lần mỗi chiến dịch**,  \n",
    "và **chuyển trọng tâm sang chất lượng cuộc gọi thay vì tần suất**,  \n",
    "nhằm **tối ưu hiệu quả và giảm chi phí nhân sự**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7268fb2",
   "metadata": {},
   "source": [
    "#### 2.2. Lịch sử liên hệ – `pdays` và `has_contact_before`\n",
    "\n",
    "→ **Mục tiêu:** tìm hiểu **tác động của việc tái liên hệ** với khách hàng **đã từng được gọi trước đây**.\n",
    "\n",
    "**Cần phân tích:**\n",
    "\n",
    "- So sánh **tỷ lệ “yes”** giữa hai nhóm:  \n",
    "  - **Đã từng được gọi trước** (`pdays ≠ 999`)  \n",
    "  - **Chưa từng được gọi** (`pdays = 999`)  \n",
    "- Kiểm tra xem **khoảng cách giữa hai lần liên hệ** (`pdays` nhỏ → gọi gần đây) có **ảnh hưởng đến tỷ lệ “yes”** hay không.\n",
    "\n",
    "**Câu hỏi khai thác:**\n",
    "\n",
    "- Việc **gọi lại** có giúp **tăng cơ hội thành công** không?  \n",
    "- Nếu có, **sau bao lâu gọi lại** là hợp lý?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6150bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+---------+-------------+---------------+\n",
      "|has_contact_before|total|yes_count|yes_ratio (%)|group_ratio (%)|\n",
      "+------------------+-----+---------+-------------+---------------+\n",
      "|                 0|39673|     3673|         9.26|          96.32|\n",
      "|                 1| 1515|      967|        63.83|           3.68|\n",
      "+------------------+-----+---------+-------------+---------------+\n",
      "\n",
      "+-----------+-----+---------+-------------+\n",
      "|pdays_group|total|yes_count|yes_ratio (%)|\n",
      "+-----------+-----+---------+-------------+\n",
      "|   > 5 ngày|  810|      522|        64.44|\n",
      "|   ≤ 5 ngày|  705|      445|        63.12|\n",
      "+-----------+-----+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tạo biến đánh dấu đã từng liên hệ trước đó\n",
    "df_pdays = df.withColumn(\"has_contact_before\", (F.col(\"pdays\") != 999).cast(\"int\"))\n",
    "total_count = df_pdays.count()\n",
    "\n",
    "# Đếm số lượng và tỷ lệ \"yes\" theo nhóm liên hệ\n",
    "pdays_stats = (\n",
    "    df_pdays.groupBy(\"has_contact_before\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total\"),\n",
    "        F.sum((F.col(\"y\") == \"yes\").cast(\"int\")).alias(\"yes_count\")\n",
    "    )\n",
    "    .withColumn(\"yes_ratio (%)\", F.round(F.col(\"yes_count\") / F.col(\"total\") * 100, 2))\n",
    "    .withColumn(\"group_ratio (%)\", F.round(F.col(\"total\") / total_count * 100, 2))\n",
    "    .orderBy(\"has_contact_before\")\n",
    ")\n",
    "pdays_stats.show()\n",
    "\n",
    "# Chỉ giữ những khách hàng đã từng được liên hệ (pdays != 999)\n",
    "df_recontacted = df.filter(F.col(\"pdays\") != 999)\n",
    "\n",
    "# Phân nhóm khoảng cách gọi lại\n",
    "pdays_grouped = (\n",
    "    df_recontacted.withColumn(\n",
    "        \"pdays_group\",\n",
    "        F.when(F.col(\"pdays\") <= 5, \"≤ 5 ngày\")\n",
    "         .otherwise(\"> 5 ngày\")\n",
    "    )\n",
    "    .groupBy(\"pdays_group\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total\"),\n",
    "        F.sum((F.col(\"y\") == \"yes\").cast(\"int\")).alias(\"yes_count\")\n",
    "    )\n",
    "    .withColumn(\"yes_ratio (%)\", F.round(F.col(\"yes_count\") / F.col(\"total\") * 100, 2))\n",
    "    .orderBy(\"pdays_group\")\n",
    ")\n",
    "pdays_grouped.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ac31a",
   "metadata": {},
   "source": [
    "Phân tích cho thấy \n",
    "- **Khách hàng từng được liên hệ trước đó** có **tỷ lệ đồng ý rất cao (~63.8%)**,  \n",
    "cao gấp nhiều lần so với nhóm **chưa từng được gọi (9.3%)**.  \n",
    "\n",
    "- Giữa nhóm **được gọi lại trong vòng 5 ngày** và **sau 5 ngày**, tỷ lệ “yes” gần như **tương đương (63–64%)**.\n",
    "\n",
    "- Chỉ **3.68%** khách hàng từng được gọi trước đó, nghĩa là **hơn 96%** là lần đầu tiên được liên hệ.  Điều này xác nhận chiến dịch marketing của ngân hàng chủ yếu là **cold call**, không phải **chăm sóc khách hàng cũ**.  \n",
    "\n",
    "👉 **Kết luận:**  \n",
    "**Tái liên hệ khách hàng cũ** là một **chiến lược hiệu quả rõ rệt**,  \n",
    "trong khi **khoảng cách giữa hai lần gọi không ảnh hưởng đáng kể**.\n",
    "\n",
    "**Đề xuất:**  \n",
    "Ngân hàng nên **ưu tiên xây dựng chiến dịch follow-up có chọn lọc**  \n",
    "thay vì **tập trung quá nhiều vào gọi mới (cold call)**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a956df",
   "metadata": {},
   "source": [
    "#### 2.3. Số lần liên hệ trong các chiến dịch trước – `previous`\n",
    "\n",
    "→ **Mục tiêu:** đánh giá xem **lịch sử được gọi nhiều lần trước đây** có giúp **tăng xác suất khách hàng “yes”** trong chiến dịch hiện tại hay không.\n",
    "\n",
    "**Cần phân tích:**\n",
    "\n",
    "- Tính **tỷ lệ “yes” theo giá trị `previous`** (0, 1, 2, …).  \n",
    "- Kiểm tra xem **khách hàng từng được liên hệ 1–2 lần trước đó** có **dễ đồng ý hơn** so với nhóm chưa từng liên hệ không.\n",
    "\n",
    "**Câu hỏi khai thác:**\n",
    "\n",
    "- “**Khách hàng quen thuộc**” có thực sự **tiềm năng hơn** không?  \n",
    "- Có nên **tập trung vào nhóm đã liên hệ nhiều lần trong quá khứ** để tăng hiệu quả chiến dịch?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8d979c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---------+-------------+\n",
      "|previous|total|yes_count|yes_ratio (%)|\n",
      "+--------+-----+---------+-------------+\n",
      "|       0|35563|     3141|         8.83|\n",
      "|       1| 4561|      967|         21.2|\n",
      "|       2|  754|      350|        46.42|\n",
      "|       3|  216|      128|        59.26|\n",
      "|       4|   70|       38|        54.29|\n",
      "|       5|   18|       13|        72.22|\n",
      "|       6|    5|        3|         60.0|\n",
      "|       7|    1|        0|          0.0|\n",
      "+--------+-----+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Tính tỷ lệ yes theo số lần được liên hệ trong các chiến dịch trước\n",
    "previous_stats = (\n",
    "    df.groupBy(\"previous\")\n",
    "      .agg(\n",
    "          F.count(\"*\").alias(\"total\"),\n",
    "          F.sum((F.col(\"y\") == \"yes\").cast(\"int\")).alias(\"yes_count\")\n",
    "      )\n",
    "      .withColumn(\"yes_ratio (%)\", F.round(F.col(\"yes_count\") / F.col(\"total\") * 100, 2))\n",
    "      .orderBy(\"previous\")\n",
    ")\n",
    "\n",
    "previous_stats.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f23f3",
   "metadata": {},
   "source": [
    "Phân tích cho thấy **tỷ lệ đồng ý tăng rõ rệt** theo **số lần khách hàng từng được liên hệ trong quá khứ**:\n",
    "\n",
    "- **previous = 0:** 8.83% khách hàng đồng ý.  \n",
    "- **previous = 1–2:** 21–46%, tăng gấp **2–5 lần**.  \n",
    "- **previous ≥ 3:** ~55–72%, dù số mẫu ít hơn.\n",
    "\n",
    "👉 **Kết luận:**  \n",
    "**Khách hàng đã từng được liên hệ trước đây** là nhóm **có tiềm năng cao**,  \n",
    "với **xác suất “yes” cao hơn nhiều** so với khách hàng mới.\n",
    "\n",
    "**Đề xuất:**  \n",
    "Tập trung **chăm sóc và tái liên hệ nhóm khách hàng quen thuộc**,  \n",
    "thay vì **dàn trải nguồn lực cho nhóm chưa từng tương tác**.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752c73d",
   "metadata": {},
   "source": [
    "### 3 – Thời lượng và hành vi cuộc gọi (duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee0bcf",
   "metadata": {},
   "source": [
    "#### 3.1. Thời lượng và hành vi cuộc gọi – `duration`\n",
    "\n",
    "→ **Mục tiêu:** phân tích xem **thời lượng cuộc gọi** có liên quan đến **khả năng khách hàng đồng ý (“yes”)** hay không,  \n",
    "từ đó hiểu rõ **mức độ quan tâm và tương tác** của khách hàng trong quá trình tư vấn.\n",
    "\n",
    "**Cần phân tích:**\n",
    "\n",
    "- So sánh **thời lượng trung bình (duration)** giữa hai nhóm **“yes”** và **“no”**.  \n",
    "- Tính **tỷ lệ “yes” theo nhóm độ dài cuộc gọi**: *ngắn*, *trung bình*, *dài*.\n",
    "\n",
    "**Câu hỏi khai thác:**\n",
    "\n",
    "- Liệu **cuộc gọi kéo dài hơn** có thực sự **dẫn đến khả năng đồng ý cao hơn**?  \n",
    "- Có thể **xác định ngưỡng thời lượng tối thiểu** để nhận biết **cuộc gọi tiềm năng thành công** không?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24c2e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "|  y|avg_duration_sec|\n",
      "+---+----------------+\n",
      "| no|          220.84|\n",
      "|yes|          553.19|\n",
      "+---+----------------+\n",
      "\n",
      "+--------------------+-----+---------+-------------+\n",
      "|      duration_group|total|yes_count|yes_ratio (%)|\n",
      "+--------------------+-----+---------+-------------+\n",
      "|         dài (>300s)|11204|     3122|        27.87|\n",
      "|        ngắn (≤120s)|12917|      166|         1.29|\n",
      "|trung bình (121–3...|17067|     1352|         7.92|\n",
      "+--------------------+-----+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Thời lượng trung bình giữa hai nhóm \"yes\" và \"no\"\n",
    "duration_avg = (\n",
    "    df.groupBy(\"y\")\n",
    "      .agg(F.round(F.avg(\"duration\"), 2).alias(\"avg_duration_sec\"))\n",
    "      .orderBy(\"y\")\n",
    ")\n",
    "duration_avg.show()\n",
    "\n",
    "# 2) Tỷ lệ \"yes\" theo nhóm độ dài cuộc gọi: ngắn (≤120s), trung bình (121–300s), dài (>300s)\n",
    "duration_bins = (\n",
    "    df.withColumn(\n",
    "        \"duration_group\",\n",
    "        F.when(F.col(\"duration\") <= 120, \"ngắn (≤120s)\")\n",
    "         .when(F.col(\"duration\") <= 300, \"trung bình (121–300s)\")\n",
    "         .otherwise(\"dài (>300s)\")\n",
    "    )\n",
    "    .groupBy(\"duration_group\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total\"),\n",
    "        F.sum((F.col(\"y\") == \"yes\").cast(\"int\")).alias(\"yes_count\")\n",
    "    )\n",
    "    .withColumn(\"yes_ratio (%)\", F.round(F.col(\"yes_count\")/F.col(\"total\")*100, 2))\n",
    "    .orderBy(\"duration_group\")\n",
    ")\n",
    "\n",
    "duration_bins.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6056e29",
   "metadata": {},
   "source": [
    "**Phân tích cho thấy:**  \n",
    "Thời lượng cuộc gọi trung bình của nhóm **“yes”** cao gấp hơn **2 lần** so với nhóm **“no”**:\n",
    "\n",
    "- **Nhóm “no”:** trung bình **220.84 giây**.  \n",
    "- **Nhóm “yes”:** trung bình **553.19 giây**.\n",
    "\n",
    "**Phân nhóm độ dài cuộc gọi:**\n",
    "\n",
    "- **Ngắn (≤120s):** tỷ lệ đồng ý chỉ **1.29%** trên tổng **12,917 cuộc gọi**.  \n",
    "- **Trung bình (121–300s):** tỷ lệ tăng lên **7.92%** trên **17,067 cuộc gọi**.  \n",
    "- **Dài (>300s):** tỷ lệ “yes” vọt lên **27.87%** trên **11,204 cuộc gọi**.\n",
    "\n",
    "👉 **Kết luận:**  \n",
    "Các cuộc gọi kéo dài **hơn 5 phút** có khả năng thành công **cao gấp 3–5 lần** so với các cuộc gọi ngắn.  \n",
    "Điều này cho thấy **mức độ tương tác và thời gian tư vấn** là **yếu tố quyết định quan trọng** cho việc thuyết phục khách hàng.\n",
    "\n",
    "**Đề xuất:**  \n",
    "Ngân hàng nên **tập trung vào chất lượng cuộc gọi hơn là số lượng**,  \n",
    "khuyến khích nhân viên **duy trì cuộc trò chuyện lâu hơn** với **những khách hàng tiềm năng**,  \n",
    "thay vì **kết thúc sớm**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f2a11",
   "metadata": {},
   "source": [
    "### 4. Tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f4735",
   "metadata": {},
   "source": [
    "#### 4.1.a – Chuẩn hóa biến mục tiêu và tạo biến phụ\n",
    "\n",
    "**Mục tiêu:**\n",
    "\n",
    "- Chuyển `y` thành dạng nhị phân (`0/1`).\n",
    "- Tạo biến `has_contact_before = 1` nếu `pdays != 999`, `0` nếu ngược lại (đã từng liên hệ).\n",
    "- Giới hạn giá trị `campaign ≤ 10` để tránh outlier cực lớn (bạn từng phát hiện có người bị gọi >50 lần).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2184c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('y_binary', F.when(F.col('y') == 'yes', 1).otherwise(0))\n",
    "\n",
    "df = df.withColumn('has_contact_before', (F.col('pdays') != 999).cast('int'))\n",
    "\n",
    "df = df.withColumn('campaign_capped', F.when(F.col('campaign') > 10, 10).otherwise(F.col('campaign')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c74f4",
   "metadata": {},
   "source": [
    "#### 4.1.b – Mã hóa biến phân loại\n",
    "\n",
    "**Mục tiêu:**\n",
    "\n",
    "- Chuyển các biến dạng chữ (string) sang dạng số để mô hình hiểu được.  \n",
    "- Trong dataset bạn có ba biến phân loại chính:\n",
    "  - `contact`\n",
    "  - `month`\n",
    "  - `day_of_week`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47115ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+-----+-----------+--------------+\n",
      "|contact  |contact_index|contact_vec  |month|month_index|month_vec     |\n",
      "+---------+-------------+-------------+-----+-----------+--------------+\n",
      "|telephone|1.0          |(2,[1],[1.0])|may  |0.0        |(10,[0],[1.0])|\n",
      "|telephone|1.0          |(2,[1],[1.0])|may  |0.0        |(10,[0],[1.0])|\n",
      "|telephone|1.0          |(2,[1],[1.0])|may  |0.0        |(10,[0],[1.0])|\n",
      "|telephone|1.0          |(2,[1],[1.0])|may  |0.0        |(10,[0],[1.0])|\n",
      "|telephone|1.0          |(2,[1],[1.0])|may  |0.0        |(10,[0],[1.0])|\n",
      "+---------+-------------+-------------+-----+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "cat_cols = [\"contact\", \"month\", \"day_of_week\"]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_index\", handleInvalid=\"keep\") for c in cat_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{c}_index\", outputCol=f\"{c}_vec\") for c in cat_cols]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "df_encoded = pipeline.fit(df).transform(df)\n",
    "\n",
    "df_encoded.select(\"contact\", \"contact_index\", \"contact_vec\", \n",
    "                  \"month\", \"month_index\", \"month_vec\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca29a2a",
   "metadata": {},
   "source": [
    "#### Vì sao dùng StringIndexer + OneHotEncoder\n",
    "\n",
    "**Giải thích:**\n",
    "\n",
    "- Các mô hình như **Logistic Regression**, **MLP** cần dữ liệu dạng **vector số** — mỗi cột đại diện cho một đặc trưng riêng.  \n",
    "- Dữ liệu chỉ có ít giá trị phân loại (`contact`, `month`, `day_of_week`), nên **One-Hot Encoding** không gây tăng chiều dữ liệu quá mức.  \n",
    "- `StringIndexer` biến chuỗi thành mã số để `OneHotEncoder` hiểu được, giúp pipeline **ổn định và tái sử dụng cho dữ liệu mới**.  \n",
    "- Nếu chỉ dùng **Label Encoding**, mô hình sẽ hiểu sai rằng các giá trị có **thứ tự**, làm sai ý nghĩa của biến.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868b4d7",
   "metadata": {},
   "source": [
    "#### 4.1.c – Chia dữ liệu Train / Validation / Test\n",
    "\n",
    "**Mục tiêu:**\n",
    "\n",
    "Tách dữ liệu thành 3 phần để:\n",
    "\n",
    "- **Train mô hình (70%)**  \n",
    "- **Validation** để tinh chỉnh tham số (**15%**)  \n",
    "- **Test** để đánh giá cuối cùng (**15%**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf6499bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.window.WindowSpec object at 0x00000230FD2F4550>\n",
      "Counts: 28831 6178 6179\n",
      "\n",
      "Train label distribution:\n",
      "+--------+-----+---------+\n",
      "|y_binary|count|ratio (%)|\n",
      "+--------+-----+---------+\n",
      "|       0|25583|    88.73|\n",
      "|       1| 3248|    11.27|\n",
      "+--------+-----+---------+\n",
      "\n",
      "\n",
      "Validation label distribution:\n",
      "+--------+-----+---------+\n",
      "|y_binary|count|ratio (%)|\n",
      "+--------+-----+---------+\n",
      "|       0| 5482|    88.73|\n",
      "|       1|  696|    11.27|\n",
      "+--------+-----+---------+\n",
      "\n",
      "\n",
      "Test label distribution:\n",
      "+--------+-----+---------+\n",
      "|y_binary|count|ratio (%)|\n",
      "+--------+-----+---------+\n",
      "|       0| 5483|    88.74|\n",
      "|       1|  696|    11.26|\n",
      "+--------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = Window.partitionBy('y_binary').orderBy(F.rand(seed = 42))\n",
    "print(w)\n",
    "df_strat = (\n",
    "    df_encoded.withColumn('pr', F.percent_rank().over(w))\n",
    ")\n",
    "\n",
    "#Chia ty le\n",
    "train_df = df_strat.filter(F.col('pr') < 0.7).drop('pr')\n",
    "val_df = df_strat.filter((F.col('pr') >= 0.7) & (F.col('pr') < 0.85)).drop('pr')\n",
    "test_df = df_strat.filter(F.col('pr') >= 0.85).drop('pr')\n",
    "\n",
    "# Kiểm tra quy mô & phân bố nhãn\n",
    "print(\"Counts:\", train_df.count(), val_df.count(), test_df.count())\n",
    "\n",
    "for name, subset in [(\"Train\", train_df), (\"Validation\", val_df), (\"Test\", test_df)]:\n",
    "    print(f\"\\n{name} label distribution:\")\n",
    "    total = subset.count()\n",
    "    subset.groupBy(\"y_binary\").agg(\n",
    "        F.count('*').alias('count')\n",
    "    ).withColumn('ratio (%)', F.round(F.col('count')/total * 100, 2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffceef3",
   "metadata": {},
   "source": [
    "#### Lý do chọn phương pháp chia dữ liệu\n",
    "\n",
    "**Giải thích:**\n",
    "\n",
    "- Bài toán sử dụng **Stratified Hold-out (70/15/15)** để đảm bảo tỷ lệ nhãn `yes/no` được giữ ổn định trong từng tập **Train**, **Validation** và **Test**.  \n",
    "- Phương pháp này phù hợp vì **dữ liệu đủ lớn (~41k mẫu, tỷ lệ yes ≈ 11%)**, giúp mô hình học được xu hướng tổng quát mà không cần lặp nhiều lần như **K-fold**.\n",
    "\n",
    "**Ưu điểm của Stratified Hold-out:**\n",
    "\n",
    "- Nhanh, dễ triển khai trong **PySpark**.  \n",
    "- Giữ đúng phân phối nhãn cho bài toán **mất cân bằng**.  \n",
    "- Hạn chế được **chi phí tính toán** so với K-fold, vốn phải huấn luyện mô hình nhiều lần.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f151d",
   "metadata": {},
   "source": [
    "#### 4.1.d – Class weighting (mặc định) + tuỳ chọn undersampling\n",
    "\n",
    "**Mục tiêu:**\n",
    "\n",
    "Giảm thiên lệch do `yes ≈ 11%` nhưng không làm mất dữ liệu quan trọng.  \n",
    "Chiến lược mặc định: **gán trọng số theo lớp** trên tập **train** (validation/test giữ nguyên để đánh giá công bằng).\n",
    "\n",
    "#### Công thức tổng quát cho trọng số cân bằng\n",
    "\n",
    "**Công thức:**\n",
    "\n",
    "$$\n",
    "w_i = \\frac{N}{k \\times n_i}\n",
    "$$\n",
    "\n",
    "**Trong đó:**\n",
    "\n",
    "- $w_i$: trọng số của lớp *i*  \n",
    "- $N$: tổng số mẫu trong tập huấn luyện  \n",
    "- $n_i$: số mẫu thuộc lớp *i*  \n",
    "- $k$: số lượng lớp (với bài toán nhị phân, $k = 2$)\n",
    "\n",
    "→ Khi lớp “yes” chiếm ít, $n_{\\text{yes}}$ nhỏ → $w_{\\text{yes}}$ lớn hơn $w_{\\text{no}}$.  \n",
    "Nói cách khác, mỗi lỗi dự đoán sai của lớp thiểu số sẽ bị **phạt nặng hơn** trong quá trình tối ưu hàm mất mát,  \n",
    "giúp mô hình học **cân bằng giữa hai lớp** mà không cần thay đổi dữ liệu gốc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20c8ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|y_binary| avg_w|\n",
      "+--------+------+\n",
      "|       0|0.5635|\n",
      "|       1|4.4383|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = {r['y_binary']: r['count'] for r in train_df.groupBy('y_binary').count().collect()}\n",
    "\n",
    "n_pos = cnt.get(1, 0)\n",
    "n_neg = cnt.get(0, 0)\n",
    "n_tot = n_pos + n_neg\n",
    "\n",
    "# Trọng số cân bằng kiểu \"balanced\":\n",
    "# w_pos = N / (2 * N_pos), w_neg = N / (2 * N_neg)\n",
    "w_pos = float(n_tot) / (2.0 * n_pos)\n",
    "w_neg = float(n_tot) / (2.0 * n_neg)\n",
    "\n",
    "# Gán trọng số cho TRAIN; Val/Test không gán để đánh giá trung thực\n",
    "train_w = train_df.withColumn(\n",
    "    \"class_weight\",\n",
    "    F.when(F.col(\"y_binary\") == 1, F.lit(w_pos)).otherwise(F.lit(w_neg))\n",
    ")\n",
    "\n",
    "train_w.groupBy(\"y_binary\").agg(F.round(F.avg(\"class_weight\"),4).alias(\"avg_w\")).orderBy(\"y_binary\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750a79e",
   "metadata": {},
   "source": [
    "#### Giải thích lựa chọn phương pháp class weighting\n",
    "\n",
    "**Lý do:**\n",
    "\n",
    "- Tập dữ liệu đủ lớn, **không cần nhân bản mẫu thiểu số**.  \n",
    "- Nhiều biến phân loại nên **SMOTE không phù hợp**.  \n",
    "- Các mô hình **Logistic Regression**, **CatBoost** và **MLP** đều hỗ trợ weighting trực tiếp.  \n",
    "- Giữ nguyên toàn bộ dữ liệu thật, giúp mô hình học **cân bằng và ổn định hơn**.\n",
    "\n",
    "**Kết luận:**\n",
    "\n",
    "Sử dụng **class weighting** giúp duy trì toàn bộ dữ liệu gốc, giảm thiên lệch,  \n",
    "và phù hợp với cả ba mô hình huấn luyện chính của nhóm.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99813dfe",
   "metadata": {},
   "source": [
    "#### 4.1.e – Assemble features\n",
    "\n",
    "**Mục tiêu:**  \n",
    "Gom toàn bộ các đặc trưng đầu vào (bao gồm cả dữ liệu **số** và **one-hot encoding**) thành **một cột vector duy nhất** có tên `features`, để sẵn sàng đưa vào giai đoạn huấn luyện mô hình.\n",
    "\n",
    "**Lưu ý:**  \n",
    "Không bao gồm trường **`duration`** trong quá trình tổng hợp — nhằm **tránh rò rỉ thông tin** liên quan đến kết quả sau khi cuộc gọi đã kết thúc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "feature_cols = ['previous', 'has_contact_before', 'campaign_capped',\n",
    "                'contact_vec', 'month_vec', 'day_of_week_vec']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features_unscaled')\n",
    "scaler    = StandardScaler(inputCol='features_unscaled', outputCol='features',\n",
    "                           withMean=True, withStd=True)\n",
    "\n",
    "# Fit đúng 1 lần trên TRAIN\n",
    "pipeline_scale = Pipeline(stages=[assembler, scaler])\n",
    "scale_model = pipeline_scale.fit(train_w)\n",
    "\n",
    "# Transform 3 tập (không fit lại)\n",
    "train_ready = scale_model.transform(train_w).select('features','y_binary','class_weight')\n",
    "val_ready   = scale_model.transform(val_df).select('features','y_binary')\n",
    "test_ready  = scale_model.transform(test_df).select('features','y_binary')\n",
    "\n",
    "# Persist cái dùng nhiều\n",
    "train_ready = train_ready.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "_ = train_ready.count()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea494c",
   "metadata": {},
   "source": [
    "### 5. Huấn luyện mô hình\n",
    "\n",
    "Mục tiêu của bước này là **xây dựng mô hình học máy** có khả năng **dự đoán xác suất khách hàng sẽ đồng ý tham gia sản phẩm (`y = yes`)** dựa trên các thông tin có sẵn như nhân khẩu học, nghề nghiệp, kênh liên lạc và lịch sử chiến dịch marketing.  \n",
    "\n",
    "Kết quả huấn luyện giúp mô hình học được **mối quan hệ giữa đặc trưng đầu vào và hành vi phản hồi của khách hàng**, từ đó hỗ trợ doanh nghiệp **xác định nhóm khách hàng tiềm năng nhất để tiếp cận trước**, giảm chi phí gọi điện và tăng hiệu quả marketing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d779513",
   "metadata": {},
   "source": [
    "#### 5.1.a – Cấu hình & Train mô hình (dùng `class_weight`)\n",
    "\n",
    "**Mục tiêu:**  \n",
    "Huấn luyện mô hình **baseline đầu tiên** trên tập dữ liệu `train_ready` để làm **mốc so sánh** với các mô hình sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d1425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "|rawPrediction                             |probability                             |prediction|y_binary|\n",
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "|[1.498029288056012,-1.498029288056012]    |[0.8172803675270653,0.18271963247293466]|0.0       |0       |\n",
      "|[1.262208047674275,-1.262208047674275]    |[0.7794059766980153,0.22059402330198474]|0.0       |0       |\n",
      "|[1.196569153234042,-1.196569153234042]    |[0.7679138927381268,0.23208610726187318]|0.0       |0       |\n",
      "|[0.34745760641059786,-0.34745760641059786]|[0.5860009196287119,0.4139990803712881] |0.0       |0       |\n",
      "|[-3.651301973313404,3.651301973313404]    |[0.02530057611851298,0.974699423881487] |1.0       |0       |\n",
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"y_binary\",\n",
    "    weightCol=\"class_weight\",   \n",
    "    predictionCol=\"prediction\",\n",
    "    probabilityCol=\"probability\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    family=\"binomial\",\n",
    "    elasticNetParam=0.0,      \n",
    "    regParam=0.01,\n",
    "    maxIter=100,\n",
    "    standardization=True\n",
    ")\n",
    "\n",
    "lr_model = lr.fit(train_ready)\n",
    "\n",
    "\n",
    "# Dự đoán trên tập validation để chuẩn bị đánh giá ở bước 5.1.b\n",
    "val_pred = lr_model.transform(val_ready).select(\"rawPrediction\",\"probability\",\"prediction\",\"y_binary\")\n",
    "val_pred.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ef8cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(pred_data, label_col=\"y_binary\", pred_col=\"prediction\", raw_col=\"rawPrediction\"):\n",
    "    from pyspark.sql import functions as F\n",
    "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "    cm = (\n",
    "        pred_data\n",
    "        .groupBy(label_col, pred_col)\n",
    "        .count()\n",
    "        .orderBy(label_col, pred_col)\n",
    "    )\n",
    "    cm.show()\n",
    "\n",
    "    agg = (\n",
    "        pred_data\n",
    "        .withColumn(\"tp\", F.when((F.col(pred_col)==1) & (F.col(label_col)==1), 1).otherwise(0))\n",
    "        .withColumn(\"fp\", F.when((F.col(pred_col)==1) & (F.col(label_col)==0), 1).otherwise(0))\n",
    "        .withColumn(\"tn\", F.when((F.col(pred_col)==0) & (F.col(label_col)==0), 1).otherwise(0))\n",
    "        .withColumn(\"fn\", F.when((F.col(pred_col)==0) & (F.col(label_col)==1), 1).otherwise(0))\n",
    "        .agg(F.sum(\"tp\").alias(\"tp\"),\n",
    "             F.sum(\"fp\").alias(\"fp\"),\n",
    "             F.sum(\"tn\").alias(\"tn\"),\n",
    "             F.sum(\"fn\").alias(\"fn\"),\n",
    "             F.count(\"*\").alias(\"n\"))\n",
    "        .collect()[0]\n",
    "    )\n",
    "\n",
    "    tp, fp, tn, fn, n = [agg[x] for x in [\"tp\",\"fp\",\"tn\",\"fn\",\"n\"]]\n",
    "    acc = (tp + tn) / n if n else 0.0\n",
    "    prec = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    rec  = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1   = 2 * prec * rec / (prec + rec) if (prec + rec) else 0.0\n",
    "    print(f\"Accuracy={acc:.4f} | Precision={prec:.4f} | Recall={rec:.4f} | F1={f1:.4f}\")\n",
    "\n",
    "    # ROC-AUC và PR-AUC nếu có rawPrediction\n",
    "    if raw_col in pred_data.columns:\n",
    "        e_roc = BinaryClassificationEvaluator(labelCol=label_col, rawPredictionCol=raw_col, metricName=\"areaUnderROC\")\n",
    "        e_pr  = BinaryClassificationEvaluator(labelCol=label_col, rawPredictionCol=raw_col, metricName=\"areaUnderPR\")\n",
    "        print(f\"ROC-AUC={e_roc.evaluate(pred_data):.4f} | PR-AUC={e_pr.evaluate(pred_data):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c74263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+\n",
      "|y_binary|prediction|count|\n",
      "+--------+----------+-----+\n",
      "|       0|       0.0| 4790|\n",
      "|       0|       1.0|  692|\n",
      "|       1|       0.0|  354|\n",
      "|       1|       1.0|  342|\n",
      "+--------+----------+-----+\n",
      "\n",
      "Accuracy : 0.8307\n",
      "Precision: 0.3308\n",
      "Recall   : 0.4914\n",
      "F1-score : 0.3954\n",
      "Positive rate (true +): 0.1127\n",
      "ROC-AUC : 0.7315\n",
      "PR-AUC  : 0.3740\n"
     ]
    }
   ],
   "source": [
    "evaluation(val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d14e0",
   "metadata": {},
   "source": [
    "#### 5.1.b – Tìm siêu tham số và tối ưu ngưỡng dự đoán (threshold) theo F1 trên validation\n",
    "\n",
    "**Mục tiêu:**  \n",
    "Mô hình **Logistic Regression** mặc định sử dụng ngưỡng **0.5** để phân loại, tuy nhiên với tập dữ liệu có tỷ lệ lớp “yes” thấp (~11%), ngưỡng này thường **thiếu nhạy** (recall thấp).  \n",
    "Do đó, cần **quét qua nhiều giá trị ngưỡng** (ví dụ: từ 0.1 đến 0.9) ngoài ra cần tìm các bộ tham số thích hợp tối ưu cho F1-score, sau đó:\n",
    "\n",
    "1. Tính **Precision**, **Recall** và **F1-score** cho từng ngưỡng.  \n",
    "2. Chọn **ngưỡng có F1 cao nhất** làm giá trị tối ưu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bac7cd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-by-F1 params: {'regParam': 0.01, 'elasticNetParam': 1.0, 'maxIter': 50, 'thr': 0.51}\n",
      "VAL @T=0.51 -> F1=0.4031 | P=0.3476 | R=0.4799\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "# Grid nhỏ, thiên về bớt “phạt” để tăng recall\n",
    "reg_list = [0.0005, 0.001, 0.01, 0.05]\n",
    "en_list  = [0.0, 0.5, 1.0]     # L2 / mix / L1\n",
    "mi_list  = [50, 100]\n",
    "\n",
    "def max_f1_on_validation(model):\n",
    "    # tính p1\n",
    "    val_scored = (model.transform(val_ready)\n",
    "                        .select(\"y_binary\", vector_to_array(\"probability\").getItem(1).alias(\"p1\"))\n",
    "                        .cache())\n",
    "    # quét ngưỡng\n",
    "    best = {\"f1\": -1}\n",
    "    for t in [round(0.02 + 0.01*i, 2) for i in range(80)]:  # 0.02..0.81\n",
    "        pred = val_scored.select(\"y_binary\", (F.col(\"p1\") >= F.lit(t)).cast(\"int\").alias(\"pred\"))\n",
    "        a = pred.agg(\n",
    "            F.sum(F.when((F.col(\"pred\")==1) & (F.col(\"y_binary\")==1), 1).otherwise(0)).alias(\"tp\"),\n",
    "            F.sum(F.when((F.col(\"pred\")==1) & (F.col(\"y_binary\")==0), 1).otherwise(0)).alias(\"fp\"),\n",
    "            F.sum(F.when((F.col(\"pred\")==0) & (F.col(\"y_binary\")==0), 1).otherwise(0)).alias(\"tn\"),\n",
    "            F.sum(F.when((F.col(\"pred\")==0) & (F.col(\"y_binary\")==1), 1).otherwise(0)).alias(\"fn\")\n",
    "        ).first()\n",
    "        tp, fp, tn, fn = a.tp, a.fp, a.tn, a.fn\n",
    "        P = tp/(tp+fp) if (tp+fp) else 0.0\n",
    "        R = tp/(tp+fn) if (tp+fn) else 0.0\n",
    "        F1 = 2*P*R/(P+R) if (P+R) else 0.0\n",
    "        if F1 > best[\"f1\"]:\n",
    "            best = {\"thr\": t, \"f1\": F1, \"prec\": P, \"rec\": R}\n",
    "    return best\n",
    "\n",
    "best = None\n",
    "for rp, en, mi in product(reg_list, en_list, mi_list):\n",
    "    lr = LogisticRegression(\n",
    "        featuresCol=\"features\", labelCol=\"y_binary\", weightCol=\"class_weight\",\n",
    "        family=\"binomial\", standardization=True,\n",
    "        regParam=rp, elasticNetParam=en, maxIter=mi\n",
    "    )\n",
    "    m = lr.fit(train_ready)\n",
    "    s = max_f1_on_validation(m)\n",
    "    if (best is None) or (s[\"f1\"] > best[\"f1\"]):\n",
    "        best = {\"regParam\": rp, \"elasticNetParam\": en, \"maxIter\": mi, **s, \"model\": m}\n",
    "\n",
    "print(\"Best-by-F1 params:\",\n",
    "      {\"regParam\":best[\"regParam\"], \"elasticNetParam\":best[\"elasticNetParam\"],\n",
    "       \"maxIter\":best[\"maxIter\"], \"thr\":best[\"thr\"]})\n",
    "print(f\"VAL @T={best['thr']:.2f} -> F1={best['f1']:.4f} | P={best['prec']:.4f} | R={best['rec']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa14532",
   "metadata": {},
   "source": [
    "#### 5.1.c – Kết quả trên tập test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff5ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "|rawPrediction                             |probability                             |prediction|y_binary|\n",
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "|[0.43308687383781813,-0.43308687383781813]|[0.6066105439912574,0.39338945600874264]|0.0       |0       |\n",
      "|[0.3674479793975853,-0.3674479793975853]  |[0.5908421766530948,0.4091578233469052] |0.0       |0       |\n",
      "|[0.43308687383781813,-0.43308687383781813]|[0.6066105439912574,0.39338945600874264]|0.0       |0       |\n",
      "|[1.812004954922738,-1.812004954922738]    |[0.8596040166539753,0.14039598334602466]|0.0       |0       |\n",
      "|[0.167012693026944,-0.167012693026944]    |[0.5416563906003695,0.4583436093996305] |0.0       |0       |\n",
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+----------+-----+\n",
      "|y_binary|prediction|count|\n",
      "+--------+----------+-----+\n",
      "|       0|       0.0| 4790|\n",
      "|       0|       1.0|  692|\n",
      "|       1|       0.0|  354|\n",
      "|       1|       1.0|  342|\n",
      "+--------+----------+-----+\n",
      "\n",
      "Accuracy : 0.8307\n",
      "Precision: 0.3308\n",
      "Recall   : 0.4914\n",
      "F1-score : 0.3954\n",
      "Positive rate (true +): 0.1127\n",
      "ROC-AUC : 0.7315\n",
      "PR-AUC  : 0.3740\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr2 = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"y_binary\",\n",
    "    weightCol=\"class_weight\",\n",
    "    predictionCol=\"prediction\",\n",
    "    probabilityCol=\"probability\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    family=\"binomial\",\n",
    "    elasticNetParam=1.0,  \n",
    "    regParam=0.01,\n",
    "    maxIter=50,\n",
    "    threshold=0.51,     \n",
    "    standardization=True\n",
    ")\n",
    "\n",
    "\n",
    "lr2_model = lr2.fit(train_ready)\n",
    "\n",
    "\n",
    "\n",
    "test_pred = lr_model.transform(test_ready).select(\"rawPrediction\",\"probability\",\"prediction\",\"y_binary\")\n",
    "test_pred.show(5, truncate=False)\n",
    "\n",
    "evaluation(val_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b42d14",
   "metadata": {},
   "source": [
    "#### 6a) Train baseline GBTClassifier trên tập train, đánh giá trên validation\n",
    "\n",
    "**Điểm khác so với Logistic Regression:**\n",
    "\n",
    "- **GBT (Gradient Boosted Trees)** là mô hình **phi tuyến** — nó cộng dồn nhiều “cây yếu” (weak learners) để tạo ra một mô hình mạnh hơn.  \n",
    "  Điều này giúp **bắt được các tương tác phi tuyến** giữa các biến đầu vào tốt hơn so với Logistic Regression, vốn chỉ học tuyến tính.\n",
    "\n",
    "- Trong Spark MLlib, **GBTClassifier không hỗ trợ `weightCol`**, khác với Logistic.  \n",
    "  Do đó, ta **giữ nguyên quy trình chia tập (Stratified split)** và **cách đánh giá** như mô hình Logistic để đảm bảo so sánh công bằng.\n",
    "\n",
    "- **Việc scale dữ liệu không ảnh hưởng đến mô hình cây.**  \n",
    "  Tuy nhiên, ta vẫn dùng các **features đã được assemble/scale ở bước 4.1e** để thống nhất pipeline huấn luyện và đánh giá.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "|rawPrediction                             |probability                             |prediction|y_binary|\n",
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "|[1.512224316074537,-1.512224316074537]    |[0.9536664931117149,0.04633350688828508]|0.0       |0       |\n",
      "|[1.6451784847369582,-1.6451784847369582]  |[0.9640965124583327,0.03590348754166728]|0.0       |0       |\n",
      "|[1.6451784847369582,-1.6451784847369582]  |[0.9640965124583327,0.03590348754166728]|0.0       |0       |\n",
      "|[1.2890444073637066,-1.2890444073637066]  |[0.9294380307116556,0.07056196928834435]|0.0       |0       |\n",
      "|[-0.12850445757989315,0.12850445757989315]|[0.4360991247342985,0.5639008752657015] |1.0       |0       |\n",
      "+------------------------------------------+----------------------------------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+----------+-----+\n",
      "|y_binary|prediction|count|\n",
      "+--------+----------+-----+\n",
      "|       0|       0.0| 5403|\n",
      "|       0|       1.0|   79|\n",
      "|       1|       0.0|  558|\n",
      "|       1|       1.0|  138|\n",
      "+--------+----------+-----+\n",
      "\n",
      "Accuracy : 0.8969\n",
      "Precision: 0.6359\n",
      "Recall   : 0.1983\n",
      "F1-score : 0.3023\n",
      "Positive rate (true +): 0.1127\n",
      "ROC-AUC : 0.7315\n",
      "PR-AUC  : 0.3740\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"y_binary\",\n",
    "    maxDepth=5,     \n",
    "    maxIter=60,     \n",
    "    stepSize=0.1,   \n",
    "    subsamplingRate=1.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "gbt_model = gbt.fit(train_ready)\n",
    "\n",
    "# Dự đoán trên validation (giống mục 5)\n",
    "val_pred_gbt = (\n",
    "    gbt_model.transform(val_ready)\n",
    "             .select(\"rawPrediction\",\"probability\",\"prediction\",\"y_binary\")\n",
    ")\n",
    "\n",
    "val_pred_gbt.show(5, truncate=False)\n",
    "\n",
    "evaluation(val_pred_gbt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56668820",
   "metadata": {},
   "source": [
    "#### 6b) Cross-validation GBT + chọn ngưỡng tối ưu theo F1\n",
    "\n",
    "**Mục tiêu:**  \n",
    "Tối ưu mô hình **Gradient Boosted Trees** bằng cách:\n",
    "- Dò **siêu tham số (hyperparameters)** qua **3-fold cross-validation** để tìm cấu hình tốt nhất về `maxDepth`, `maxIter`, `stepSize`.\n",
    "- Đánh giá mô hình theo **PR-AUC** (ưu tiên phù hợp cho dữ liệu mất cân bằng).\n",
    "- Sau khi có mô hình tốt nhất, **quét nhiều ngưỡng xác suất** để chọn **threshold cho F1-score cao nhất** trên tập validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: maxDepth= 3 | maxIter= 100 | stepSize= 0.05\n",
      "Best thr=0.20 | F1=0.4316 | P=0.4238 | R=0.4397\n"
     ]
    }
   ],
   "source": [
    "# 6b — CV GBT + chọn ngưỡng F1 (ngắn gọn)\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")  # hoặc 100 tùy tài nguyên\n",
    "\n",
    "val_ready.cache()\n",
    "_ = val_ready.count()\n",
    "\n",
    "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"y_binary\", seed=42)\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(gbt.maxDepth, [3, 5, 7])\n",
    "    .addGrid(gbt.maxIter,  [60, 100])\n",
    "    .addGrid(gbt.stepSize, [0.05, 0.1])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=gbt,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=BinaryClassificationEvaluator(labelCol=\"y_binary\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\"),\n",
    "    numFolds=3, seed=42, parallelism=1\n",
    ")\n",
    "\n",
    "best = cv.fit(train_ready).bestModel\n",
    "print(\"Best params:\",\n",
    "      \"maxDepth=\", best.getMaxDepth(),\n",
    "      \"| maxIter=\", best.getMaxIter(),\n",
    "      \"| stepSize=\", best.getStepSize())\n",
    "\n",
    "# Dự đoán trên val + lấy p(y=1)\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "# Dự đoán trên val + lấy p(y=1) theo cách an toàn cho VectorUDT\n",
    "val_probs = (\n",
    "    best.transform(val_ready)\n",
    "        .select(\n",
    "            vector_to_array(\"probability\").getItem(1).alias(\"p\"),\n",
    "            F.col(\"y_binary\").cast(\"int\").alias(\"y\")\n",
    "        )\n",
    "        .collect()\n",
    ")\n",
    "\n",
    "y = np.array([r[\"y\"] for r in val_probs], dtype=int)\n",
    "p = np.array([r[\"p\"] for r in val_probs], dtype=float)\n",
    "\n",
    "\n",
    "# Quét ngưỡng 0.05..0.95 để tối ưu F1\n",
    "ths = np.linspace(0.05, 0.95, 19)\n",
    "def f1_at(t):\n",
    "    yhat = p >= t\n",
    "    yt   = y == 1\n",
    "    tp = np.sum(yhat & yt); fp = np.sum(yhat & (~yt)); fn = np.sum((~yhat) & yt)\n",
    "    prec = tp/(tp+fp) if tp+fp>0 else 0.0\n",
    "    rec  = tp/(tp+fn) if tp+fn>0 else 0.0\n",
    "    f1   = 2*prec*rec/(prec+rec) if prec+rec>0 else 0.0\n",
    "    return f1, prec, rec\n",
    "\n",
    "best_thr, best_f1, best_p, best_r = max(((t,)+f1_at(t) for t in ths), key=lambda x: x[1])\n",
    "print(f\"Best thr={best_thr:.2f} | F1={best_f1:.4f} | P={best_p:.4f} | R={best_r:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407e3a8",
   "metadata": {},
   "source": [
    "#### 6c) Đánh giá mô hình GBT tối ưu trên tập Test\n",
    "\n",
    "**Mục tiêu:**  \n",
    "Sử dụng mô hình **GBT tốt nhất (`best`)** và **ngưỡng dự đoán tối ưu (`best_thr`)** từ bước 6b để:\n",
    "1. Đánh giá **hiệu năng cuối cùng** trên tập test chưa từng thấy trong quá trình huấn luyện.  \n",
    "2. Báo cáo các chỉ số chính: **Accuracy**, **Precision**, **Recall**, **F1**, **ROC-AUC**, **PR-AUC**.  \n",
    "3. Quan sát **ma trận nhầm lẫn** để hiểu rõ mô hình dự đoán tốt/khó ở nhóm nào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b9b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC: 0.7477\n",
      "Test PR-AUC : 0.3813\n",
      "+---+--------+-----+\n",
      "|  y|pred_thr|count|\n",
      "+---+--------+-----+\n",
      "|  0|       0| 5128|\n",
      "|  0|       1|  355|\n",
      "|  1|       0|  392|\n",
      "|  1|       1|  304|\n",
      "+---+--------+-----+\n",
      "\n",
      "Threshold=0.20 | Test Acc=0.8791 | P=0.4613 | R=0.4368 | F1=0.4487\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "assert 'best' in globals() and 'best_thr' in globals(), \"Cần chạy xong 6b để có best & best_thr.\"\n",
    "assert 'test_ready' in globals(), \"Thiếu test_ready (đã assemble + encode).\"\n",
    "\n",
    "\n",
    "test_raw = (\n",
    "    best.transform(test_ready)\n",
    "        .select(\"rawPrediction\",\"probability\",\"prediction\",\"y_binary\")\n",
    ")\n",
    "\n",
    "\n",
    "e_roc = BinaryClassificationEvaluator(labelCol=\"y_binary\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "e_pr  = BinaryClassificationEvaluator(labelCol=\"y_binary\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "print(\"Test ROC-AUC:\", round(e_roc.evaluate(test_raw), 4))\n",
    "print(\"Test PR-AUC :\", round(e_pr.evaluate(test_raw), 4))\n",
    "\n",
    "\n",
    "test_with_p = (\n",
    "    test_raw\n",
    "    .select(\n",
    "        F.col(\"y_binary\").cast(\"int\").alias(\"y\"),\n",
    "        vector_to_array(\"probability\").getItem(1).alias(\"p\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "thr = float(best_thr)\n",
    "test_scored = test_with_p.withColumn(\"pred_thr\", (F.col(\"p\") >= F.lit(thr)).cast(\"int\"))\n",
    "\n",
    "cm = test_scored.groupBy(\"y\",\"pred_thr\").count().orderBy(\"y\",\"pred_thr\")\n",
    "cm.show()\n",
    "\n",
    "\n",
    "agg = (\n",
    "    test_scored\n",
    "    .withColumn(\"tp\", F.when((F.col(\"pred_thr\")==1) & (F.col(\"y\")==1), 1).otherwise(0))\n",
    "    .withColumn(\"fp\", F.when((F.col(\"pred_thr\")==1) & (F.col(\"y\")==0), 1).otherwise(0))\n",
    "    .withColumn(\"tn\", F.when((F.col(\"pred_thr\")==0) & (F.col(\"y\")==0), 1).otherwise(0))\n",
    "    .withColumn(\"fn\", F.when((F.col(\"pred_thr\")==0) & (F.col(\"y\")==1), 1).otherwise(0))\n",
    "    .agg(F.sum(\"tp\").alias(\"tp\"), F.sum(\"fp\").alias(\"fp\"), F.sum(\"tn\").alias(\"tn\"), F.sum(\"fn\").alias(\"fn\"))\n",
    "    .collect()[0]\n",
    ")\n",
    "tp, fp, tn, fn = [int(agg[x]) for x in (\"tp\",\"fp\",\"tn\",\"fn\")]\n",
    "prec = tp/(tp+fp) if tp+fp>0 else 0.0\n",
    "rec  = tp/(tp+fn) if tp+fn>0 else 0.0\n",
    "f1   = 2*prec*rec/(prec+rec) if (prec+rec)>0 else 0.0\n",
    "acc  = (tp+tn)/(tp+tn+fp+fn)\n",
    "\n",
    "print(f\"Threshold={thr:.2f} | Test Acc={acc:.4f} | P={prec:.4f} | R={rec:.4f} | F1={f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1ee97",
   "metadata": {},
   "source": [
    "### Kết luận & Ý nghĩa mô hình\n",
    "\n",
    "#### So sánh hai mô hình\n",
    "- **Logistic Regression (LR)** là mô hình tuyến tính, đơn giản và dễ diễn giải. Sau khi điều chỉnh trọng số lớp và chọn ngưỡng tối ưu, LR đạt **F1 ≈ 0.40**, **ROC-AUC ≈ 0.73**, **PR-AUC ≈ 0.37** trên tập validation.  \n",
    "- **Gradient Boosted Trees (GBT)** là mô hình phi tuyến, mạnh hơn trong việc bắt mối quan hệ phức tạp giữa các biến. Sau khi hiệu chỉnh tham số và tối ưu ngưỡng, GBT đạt **F1 ≈ 0.43–0.45**, **ROC-AUC ≈ 0.75**, **PR-AUC ≈ 0.38** trên test — tốt hơn LR ở hầu hết các chỉ số.  \n",
    "- Nhìn chung, **GBT có độ chính xác và khả năng tổng quát cao hơn**, đặc biệt trong việc nhận diện đúng nhóm khách hàng có khả năng “yes” cao hơn trung bình (Lift ≈ 4× so với chọn ngẫu nhiên). LR vẫn hữu ích cho mục đích giải thích và kiểm chứng xu hướng của các biến.\n",
    "\n",
    "#### Ý nghĩa trong bài toán marketing\n",
    "- **Mục tiêu mô hình:** dự đoán xác suất khách hàng sẽ đồng ý tham gia sản phẩm (biến `y = yes/no`).  \n",
    "- Kết quả dự đoán giúp **ưu tiên danh sách khách hàng tiềm năng** — thay vì gọi ngẫu nhiên, nhân viên marketing có thể tập trung vào nhóm có xác suất cao nhất, **tiết kiệm chi phí và thời gian**.  \n",
    "- Việc **chọn ngưỡng tối ưu** (ví dụ 0.2–0.3) cho phép cân bằng giữa **Precision** (độ chính xác khi gọi) và **Recall** (không bỏ sót khách hàng có tiềm năng).  \n",
    "- **Ý nghĩa phân tích:** mô hình cũng giúp hiểu các yếu tố ảnh hưởng đến hành vi “yes”, như độ tuổi, tình trạng việc làm, số lần liên hệ, kênh liên lạc (`contact`), và thời điểm gọi (`month`, `day_of_week`), từ đó hỗ trợ ra quyết định marketing có cơ sở dữ liệu (data-driven marketing).\n",
    "\n",
    "#### Nguyên nhân & Hạn chế\n",
    "- **Tập dữ liệu mất cân bằng mạnh:** chỉ khoảng **11–12% khách hàng “yes”**, khiến mô hình khó học được tín hiệu thật và dễ bị thiên lệch về lớp “no”.  \n",
    "- Dù đã áp dụng **class_weight** và **chọn ngưỡng tối ưu**, nhưng **Precision và Recall vẫn giới hạn** vì dữ liệu chưa đủ phong phú và phân bố chưa đều giữa các nhóm khách hàng.  \n",
    "- **Một số đặc trưng còn nhiễu hoặc trùng lặp thông tin** (ví dụ: `previous`, `poutcome`, `campaign`) nên mô hình khó khai thác được tín hiệu rõ ràng.  \n",
    "- **Các yếu tố bên ngoài** (tâm lý khách hàng, tình hình kinh tế, chiến dịch marketing song song…) không được ghi nhận trong dữ liệu, cũng làm giảm khả năng dự đoán tuyệt đối của mô hình.\n",
    "\n",
    "**→ Kết luận:**  \n",
    "Mô hình GBT hiện là lựa chọn phù hợp nhất để triển khai thực tế, vì đạt hiệu năng cao và linh hoạt trong việc điều chỉnh ngưỡng theo chiến lược kinh doanh. Logistic Regression được giữ làm baseline để theo dõi, giải thích và so sánh định kỳ trong quá trình vận hành hệ thống dự đoán khách hàng tiềm năng.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
