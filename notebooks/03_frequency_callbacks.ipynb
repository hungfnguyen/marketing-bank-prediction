{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 — Frequency & Callback Analysis (Random Forest & GBT)\n",
    "\n",
    "## 1. Mục tiêu & phạm vi\n",
    "- Phân tích **tần suất liên hệ** và **hiệu quả tái liên hệ (callback)** để tối ưu chiến dịch marketing.  \n",
    "- Xác định các yếu tố ảnh hưởng đến khả năng khách hàng đồng ý (`y = yes`) dựa trên **hành vi gọi và lịch sử chiến dịch trước**.  \n",
    "- Xây dựng mô hình dự đoán khách hàng tiềm năng bằng **PySpark ML** (Random Forest và GBT).  \n",
    "- Tập trung vào các biến:  \n",
    "  `campaign`, `pdays`, `previous`, `poutcome`, `y`  \n",
    "  *(bỏ qua `duration` để tránh leakage, vì giá trị này chỉ có sau khi cuộc gọi diễn ra).*\n",
    "\n",
    "## 2. Chiến lược đánh giá: \n",
    "- **Tỷ lệ chia dữ liệu:** 80% train – 20% test (giữ phân phối nhãn cân bằng, seed = 42).  \n",
    "- **Huấn luyện & tuning:**  \n",
    "  - Sử dụng **Stratified K-Fold = 3** trên tập train để điều chỉnh siêu tham số (numTrees, maxDepth).  \n",
    "  - So sánh hiệu suất giữa **Random Forest** và **Gradient Boosted Trees (GBT)**.  \n",
    "- **Đánh giá mô hình:**  \n",
    "  - Sử dụng các chỉ số: **AUC**, **Accuracy**, **Precision**, **Recall**.  \n",
    "  - Mục tiêu: đạt **AUC ≥ 0.6** và mô hình ổn định với dữ liệu mất cân bằng.  \n",
    "- **Cân bằng lớp (Class Imbalance):**  \n",
    "  - Áp dụng kỹ thuật **weight balancing** trực tiếp trong mô hình.  \n",
    "  - Thử nghiệm **SMOTE** hoặc **oversampling ratio = 0.5** trên tập train để tăng mẫu “yes”.\n",
    "\n",
    "## 3. Chuẩn hóa Dữ liệu & Tiền xử lý\n",
    "- Đọc dữ liệu bằng **`spark.read.csv`** (`sep=';'`, `header=True`, `inferSchema=True`).  \n",
    "- Mã hóa biến mục tiêu: `y → y_encoded (yes=1, no=0)`.  \n",
    "- Giữ nguyên nhãn `\"nonexistent\"` cho `poutcome` như giá trị hợp lệ.  \n",
    "- Xử lý giá trị đặc biệt:  \n",
    "  - `pdays = 999` → biểu thị **“chưa từng liên hệ”**.  \n",
    "  - Tạo biến bổ sung `has_previous_campaign = (pdays != 999)`.  \n",
    "- Giới hạn giá trị ngoại lệ (cap outlier) tại **99th percentile** cho các biến `campaign` và `previous`.  \n",
    "- Loại bỏ `duration` để đảm bảo **không rò rỉ dữ liệu (leakage)** sang mô hình.  \n",
    "\n",
    "---\n",
    "**Tóm tắt:**  \n",
    "> Toàn bộ pipeline được triển khai 100% bằng **PySpark**, đảm bảo khả năng mở rộng xử lý dữ liệu lớn và tuân thủ yêu cầu kỹ thuật của môn học (Spark + PyTorch).  \n",
    "> Các bước chuẩn bị dữ liệu và chiến lược đánh giá giúp mô hình có tính tái lập và kiểm chứng hiệu quả trên tập test 20%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHẦN 0: TIỀN XỬ LÝ & CHUẨN HÓA DỮ LIỆU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:** \n",
    "Làm sạch và chuẩn hóa dữ liệu trước khi thực hiện EDA và huấn luyện mô hình, đảm bảo dữ liệu đầu vào hoàn toàn chính xác và nhất quán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-QTEB4KQ5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BDML_Frequency_Callbacks</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1dc3911cd10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, Window\n",
    "from pyspark.sql.types import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Đảm bảo artifacts ở project root\n",
    "ROOT = Path.cwd().resolve()\n",
    "if ROOT.name == \"notebooks\":\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "# Đổi CWD về root để mọi đường dẫn tương đối bám vào root\n",
    "os.chdir(ROOT)\n",
    "\n",
    "ARTIFACTS = ROOT / \"artifacts\"\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"BDML_Frequency_Callbacks\")\n",
    "    .config(\"spark.sql.session.timeZone\",\"UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu & kiểm tra tổng quan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Các bước thực hiện:**\n",
    "1. **Xác định `ROOT` và thiết lập thư mục làm việc:**  \n",
    "   - Đặt `ROOT` về **thư mục project** (chứa README.md) để tránh sinh nhầm thư mục `artifacts` trong `notebooks/`.  \n",
    "   - Tạo thư mục `artifacts/` ở project root để lưu kết quả và model.  \n",
    "\n",
    "2. **Khởi tạo SparkSession:**  \n",
    "   - Đặt timezone `UTC` nhằm đồng nhất mốc thời gian trong xử lý dữ liệu.  \n",
    "   - Sử dụng Spark cho toàn bộ pipeline để đảm bảo khả năng mở rộng (scalable).\n",
    "\n",
    "3. **Đọc dữ liệu gốc:**  \n",
    "   - Dữ liệu được đọc từ file `bank-additional-full.csv` (sep = ';').  \n",
    "   - Spark tự động suy luận kiểu dữ liệu (`inferSchema=True`).  \n",
    "\n",
    "4. **Kiểm tra tổng quan:**  \n",
    "   - Tổng số dòng: **41,188**  \n",
    "   - Tổng số cột: **21**  \n",
    "   - Không có bất kỳ giá trị **null** nào trong toàn bộ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: D:\\HocTapUTE\\2025-2026-HK1\\BDML\\Project_Final\\marketing-bank-prediction\n",
      "Data path: D:\\HocTapUTE\\2025-2026-HK1\\BDML\\Project_Final\\marketing-bank-prediction\\data\\bank-additional\\bank-additional-full.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "data_path = ROOT / \"data\" / \"bank-additional\" / \"bank-additional-full.csv\"\n",
    "print(\"Data path:\", data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 41188 | Cols: 21\n",
      "+---+---+-------+---------+-------+-------+----+-------+-----+-----------+--------+--------+-----+--------+--------+------------+--------------+-------------+---------+-----------+---+\n",
      "|age|job|marital|education|default|housing|loan|contact|month|day_of_week|duration|campaign|pdays|previous|poutcome|emp.var.rate|cons.price.idx|cons.conf.idx|euribor3m|nr.employed|y  |\n",
      "+---+---+-------+---------+-------+-------+----+-------+-----+-----------+--------+--------+-----+--------+--------+------------+--------------+-------------+---------+-----------+---+\n",
      "|0  |0  |0      |0        |0      |0      |0   |0      |0    |0          |0       |0       |0    |0       |0       |0           |0             |0            |0        |0          |0  |\n",
      "+---+---+-------+---------+-------+-------+----+-------+-----+-----------+--------+--------+-----+--------+--------+------------+--------------+-------------+---------+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .option(\"sep\", \";\")\n",
    "    .option(\"inferSchema\", True)\n",
    "    .csv(str(data_path))\n",
    ")\n",
    "\n",
    "# Tổng quan\n",
    "row_cnt = df.count()\n",
    "col_cnt = len(df.columns)\n",
    "print(f\"Rows: {row_cnt} | Cols: {col_cnt}\")\n",
    "\n",
    "# Kiểm tra null từng cột\n",
    "nulls = [F.count(F.when(F.col(f\"`{c}`\").isNull(), c)).alias(c) for c in df.columns]\n",
    "df.select(nulls).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- **Dữ liệu hoàn toàn sạch**, không cần thao tác loại bỏ hoặc thay thế giá trị thiếu.  \n",
    "- Các cột được Spark tự nhận dạng đúng kiểu dữ liệu (`int`, `double`, `string`), thuận lợi cho xử lý tiếp theo.  \n",
    "- Cấu trúc và số lượng bản ghi khớp với mô tả của bộ dataset UCI Bank Marketing, đảm bảo tính toàn vẹn.  \n",
    "- Dữ liệu hiện tại sẵn sàng cho bước **chuẩn hóa logic các biến hành vi** như `pdays`, `poutcome`, `previous`, `campaign` trong phần kế tiếp.\n",
    "\n",
    "**Kết luận:**  \n",
    "Cấu hình môi trường và dữ liệu đầu vào đã được thiết lập đúng chuẩn, đảm bảo tính tái lập (reproducibility) và tính mở rộng (scalability) cho các bước EDA và modeling tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn hóa các biến cho bài toán tần suất & tái liên hệ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Chuẩn hóa các biến hành vi chính (`campaign`, `pdays`, `previous`, `poutcome`, `y`) để đảm bảo tính nhất quán, giúp mô hình hiểu rõ hơn mối quan hệ giữa lịch sử liên hệ và kết quả chiến dịch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Các bước thực hiện:**\n",
    "1. **Mã hóa nhãn mục tiêu (`y`)**  \n",
    "   - `yes → 1`, `no → 0`, tạo cột mới `y_encoded`.\n",
    "\n",
    "2. **Tạo biến logic (`has_previous_campaign`)**  \n",
    "   - 1 nếu `pdays != 999` (từng được liên hệ trước đó),  \n",
    "   - 0 nếu `pdays = 999` (chưa từng liên hệ).\n",
    "\n",
    "3. **Phân nhóm biến `pdays`**  \n",
    "   - `Chưa từng liên hệ`, `< 7 ngày`, `7–30 ngày`, `> 30 ngày`.  \n",
    "   - Giúp nhận diện ảnh hưởng của thời gian giữa các chiến dịch.\n",
    "\n",
    "4. **Tổng hợp thống kê mô tả (Spark)**  \n",
    "   - `campaign`: Trung bình ~2.57 lần gọi, 75% khách hàng được gọi ≤3 lần.  \n",
    "   - `pdays`: 96% có giá trị 999 → đa số chưa từng được liên hệ.  \n",
    "   - `previous`: Trung bình ~0.17 → phần lớn khách hàng mới.  \n",
    "   - `poutcome`: 86% `nonexistent`, 10% `failure`, 3% `success`.  \n",
    "   - `y`: 88.7% từ chối (`no`), 11.3% đồng ý (`yes`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+------+---+---+-----------------+\n",
      "|count|min|p25|median|p75|max|mean             |\n",
      "+-----+---+---+------+---+---+-----------------+\n",
      "|41188|1  |1  |2     |3  |56 |2.567592502670681|\n",
      "+-----+---+---+------+---+---+-----------------+\n",
      "\n",
      "+-----+---+---+------+---+---+-----------------+\n",
      "|count|min|p25|median|p75|max|mean             |\n",
      "+-----+---+---+------+---+---+-----------------+\n",
      "|41188|0  |999|999   |999|999|962.4754540157328|\n",
      "+-----+---+---+------+---+---+-----------------+\n",
      "\n",
      "+-----+---+---+------+---+---+-------------------+\n",
      "|count|min|p25|median|p75|max|mean               |\n",
      "+-----+---+---+------+---+---+-------------------+\n",
      "|41188|0  |0  |0     |0  |7  |0.17296299893172767|\n",
      "+-----+---+---+------+---+---+-------------------+\n",
      "\n",
      "+-----------+-----+\n",
      "|   poutcome|count|\n",
      "+-----------+-----+\n",
      "|nonexistent|35563|\n",
      "|    failure| 4252|\n",
      "|    success| 1373|\n",
      "+-----------+-----+\n",
      "\n",
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "| no|36548|\n",
      "|yes| 4640|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets = [\"campaign\",\"pdays\",\"previous\",\"poutcome\",\"y\"]\n",
    "\n",
    "# Map y: yes/no -> 1/0 (dùng cột y_encoded)\n",
    "df = df.withColumn(\"y_encoded\", F.when(F.col(\"y\")==\"yes\", F.lit(1)).otherwise(F.lit(0)))\n",
    "\n",
    "# has_previous_campaign: 1 nếu pdays != 999 else 0\n",
    "df = df.withColumn(\"has_previous_campaign\", F.when(F.col(\"pdays\") != 999, 1).otherwise(0))\n",
    "\n",
    "# pdays_group\n",
    "df = (\n",
    "    df.withColumn(\n",
    "        \"pdays_group\",\n",
    "        F.when(F.col(\"pdays\")==999, F.lit(\"Chưa từng liên hệ\"))\n",
    "         .when(F.col(\"pdays\") < 7, \" < 7 ngày\")\n",
    "         .when(F.col(\"pdays\") < 30, \"7-30 ngày\")\n",
    "         .otherwise(\"> 30 ngày\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Thống kê mô tả các biến chính (không dùng .describe() của pandas)\n",
    "for c in [\"campaign\",\"pdays\",\"previous\"]:\n",
    "    df.agg(\n",
    "        F.count(c).alias(\"count\"),\n",
    "        F.min(c).alias(\"min\"),\n",
    "        F.percentile_approx(c, 0.25).alias(\"p25\"),\n",
    "        F.percentile_approx(c, 0.50).alias(\"median\"),\n",
    "        F.percentile_approx(c, 0.75).alias(\"p75\"),\n",
    "        F.max(c).alias(\"max\"),\n",
    "        F.mean(c).alias(\"mean\")\n",
    "    ).show(truncate=False)\n",
    "\n",
    "# Phân phối các biến phân loại\n",
    "df.groupBy(\"poutcome\").count().orderBy(F.desc(\"count\")).show()\n",
    "df.groupBy(\"y\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nhận xét:\n",
    "- Dữ liệu phản ánh đúng thực tế chiến dịch marketing: **đa số khách hàng chưa từng được liên hệ hoặc từng thất bại trước đó**.  \n",
    "- Các biến mới (`has_previous_campaign`, `pdays_group`) giúp mô hình dễ dàng nhận biết nhóm “khách hàng cũ” và “khách hàng mới”.  \n",
    "- Phân phối mất cân bằng (`yes` chỉ ~11%) → cần lưu ý khi huấn luyện mô hình (sẽ xử lý trong phần sau).  \n",
    "- Đây là bước **feature engineering quan trọng** để chuyển dữ liệu thô thành thông tin có ý nghĩa hành vi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kiểm tra và xử lý outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Kiểm tra xem các biến định lượng chính (`campaign`, `previous`, `pdays`) có xuất hiện giá trị ngoại lệ không hợp lý và xử lý để tránh làm sai lệch kết quả mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Các bước thực hiện:**\n",
    "1. **Tính phân vị (percentile_approx)** bằng Spark để xác định ngưỡng trên (99th percentile).  \n",
    "2. **Cắt (cap) ngoại lệ** bằng hàm `clip` (Spark `when`):  \n",
    "   - `campaign`: từ max 56 → **14** (loại bỏ giá trị cực cao).  \n",
    "   - `previous`: từ max 7 → **2**.  \n",
    "3. **Kiểm tra sau khi xử lý**  \n",
    "   - Giữ nguyên phân phối hợp lý, không làm mất thông tin thực tế."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-------------------+------------------+\n",
      "|campaign_max_before|campaign_max_after|previous_max_before|previous_max_after|\n",
      "+-------------------+------------------+-------------------+------------------+\n",
      "|                 56|                14|                  7|                 2|\n",
      "+-------------------+------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cap_at_percentile(sdf, col, p=0.99):\n",
    "    p_val = sdf.select(F.percentile_approx(F.col(col), p).alias(\"p\")).collect()[0][\"p\"]\n",
    "    return sdf.withColumn(f\"{col}_capped\", F.when(F.col(col) > p_val, p_val).otherwise(F.col(col)))\n",
    "\n",
    "df = cap_at_percentile(df, \"campaign\", 0.99)\n",
    "df = cap_at_percentile(df, \"previous\", 0.99)\n",
    "\n",
    "# Ghi nhận thay đổi max sau khi cap\n",
    "(df.agg(F.max(\"campaign\").alias(\"campaign_max_before\"),\n",
    "        F.max(\"campaign_capped\").alias(\"campaign_max_after\"),\n",
    "        F.max(\"previous\").alias(\"previous_max_before\"),\n",
    "        F.max(\"previous_capped\").alias(\"previous_max_after\"))\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nhận xét:\n",
    "- Việc cap ngoại lệ giúp ổn định mô hình, đặc biệt với các thuật toán cây (RF, GBT).  \n",
    "- Giữ được xu hướng tự nhiên của dữ liệu, tránh ảnh hưởng từ các giá trị bất thường hiếm gặp.  \n",
    "- Không cần xóa hàng dữ liệu, vì outliers vẫn hợp lý về mặt nghiệp vụ (một số khách hàng thực sự được gọi nhiều).  \n",
    "- Đây là bước xử lý dữ liệu tinh gọn giúp mô hình **tập trung vào nhóm khách hàng phổ biến (1–3 lần gọi)** thay vì bị lệch bởi điểm cực trị.\n",
    "\n",
    "---\n",
    "\n",
    "**Kết luận chung:**  \n",
    "Dữ liệu sau chuẩn hóa và xử lý outliers **đã sẵn sàng cho các bước EDA và mô hình hóa tiếp theo** (Random Forest & GBT).  \n",
    "Các biến hành vi chính được tái cấu trúc hợp lý, giúp cải thiện tính giải thích và độ ổn định của mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHẦN 1: EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu tổng quát:**  \n",
    "Phân tích hành vi khách hàng dựa trên tần suất liên hệ và lịch sử tương tác để xác định yếu tố ảnh hưởng đến khả năng khách hàng đồng ý mở tài khoản gửi tiết kiệm (`y = yes`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 1: Phân tích biến campaign (Số lần gọi trong chiến dịch hiện tại)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Xác định mối quan hệ giữa **số lần gọi (`campaign`)** và **tỷ lệ phản hồi tích cực**, từ đó tìm ra ngưỡng liên hệ tối ưu.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+---------+------------------+\n",
      "|campaign_capped|total|yes_count|success_rate      |\n",
      "+---------------+-----+---------+------------------+\n",
      "|1              |17642|2300     |13.037070626913048|\n",
      "|2              |10570|1211     |11.456953642384105|\n",
      "|3              |5341 |574      |10.747051114023591|\n",
      "|4              |2651 |249      |9.39268200678989  |\n",
      "|5              |1599 |120      |7.5046904315197   |\n",
      "|6              |979  |75       |7.6608784473953015|\n",
      "|7              |629  |38       |6.041335453100159 |\n",
      "|8              |400  |17       |4.25              |\n",
      "|9              |283  |17       |6.007067137809187 |\n",
      "|10             |225  |12       |5.333333333333334 |\n",
      "|11             |177  |12       |6.779661016949152 |\n",
      "|12             |125  |3        |2.4               |\n",
      "|13             |92   |4        |4.3478260869565215|\n",
      "|14             |475  |8        |1.6842105263157894|\n",
      "+---------------+-----+---------+------------------+\n",
      "\n",
      "+---------------+-----+---------+------------------+\n",
      "|campaign_capped|total|yes_count|success_rate      |\n",
      "+---------------+-----+---------+------------------+\n",
      "|1              |17642|2300     |13.037070626913048|\n",
      "|2              |10570|1211     |11.456953642384105|\n",
      "|3              |5341 |574      |10.747051114023591|\n",
      "+---------------+-----+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "campaign_agg = (\n",
    "    df.groupBy(\"campaign_capped\")\n",
    "      .agg(\n",
    "          F.count(\"*\").alias(\"total\"),\n",
    "          F.sum(\"y_encoded\").alias(\"yes_count\"),\n",
    "          (F.avg(F.col(\"y_encoded\"))*100).alias(\"success_rate\")\n",
    "      )\n",
    "      .orderBy(\"campaign_capped\")\n",
    ")\n",
    "campaign_agg.show(15, truncate=False)\n",
    "\n",
    "# Lấy riêng 1..3\n",
    "campaign_agg.filter(F.col(\"campaign_capped\")<=3).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**  \n",
    "- **Gọi 1–3 lần** đạt hiệu quả cao nhất (10–13%).  \n",
    "- Khi vượt 3 lần, **hiệu quả giảm rõ rệt** → hiện tượng “over-contact”.  \n",
    "- Tần suất liên hệ cao không mang lại thêm khách hàng mà có thể gây phản cảm.  \n",
    "\n",
    "**Kết luận:**  \n",
    "- Giới hạn số lần gọi tối đa **3 lần** trong một chiến dịch để tối ưu nguồn lực và tỷ lệ thành công."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2: Phân tích biến pdays (Khoảng cách từ lần gọi trước)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Đánh giá xem khoảng cách giữa hai lần liên hệ có ảnh hưởng đến khả năng khách hàng đồng ý tham gia gửi tiết kiệm hay không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+-----------------+\n",
      "|pdays_group      |total|success_rate     |\n",
      "+-----------------+-----+-----------------+\n",
      "| < 7 ngày        |1117 |65.7117278424351 |\n",
      "|7-30 ngày        |398  |58.5427135678392 |\n",
      "|Chưa từng liên hệ|39673|9.258185667834548|\n",
      "+-----------------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdays_agg = (\n",
    "    df.groupBy(\"pdays_group\")\n",
    "      .agg(\n",
    "          F.count(\"*\").alias(\"total\"),\n",
    "          (F.avg(F.col(\"y_encoded\"))*100).alias(\"success_rate\")\n",
    "      ).orderBy(\n",
    "          F.when(F.col(\"pdays_group\")==\" < 7 ngày\", 0)\n",
    "           .when(F.col(\"pdays_group\")==\"7-30 ngày\", 1)\n",
    "           .when(F.col(\"pdays_group\")==\"> 30 ngày\", 2)\n",
    "           .otherwise(3)\n",
    "      )\n",
    ")\n",
    "pdays_agg.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**  \n",
    "- **Gọi lại trong vòng 7 ngày** giúp tăng tỷ lệ đồng ý gấp ~7 lần so với nhóm chưa từng liên hệ.  \n",
    "- Liên hệ trong khoảng **7–30 ngày** vẫn đạt hiệu quả tốt (≈58%).  \n",
    "- Nhóm chưa từng liên hệ có phản hồi thấp nhất (~9%).  \n",
    "\n",
    "**Kết luận:**  \n",
    "- **Tần suất tái liên hệ ngắn (≤7 ngày)** mang lại hiệu quả cao nhất. Nên ưu tiên follow-up khách hàng trong thời gian ngắn sau lần gọi đầu tiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 3: Phân tích biến previous (Số lần gọi trong chiến dịch trước)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Xem xét mối quan hệ giữa **số lần khách hàng được gọi trong các chiến dịch trước** và **khả năng đồng ý ở chiến dịch hiện tại**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------------------+\n",
      "|previous_group|total|success_rate      |\n",
      "+--------------+-----+------------------+\n",
      "|0 lần         |35563|8.83221325534966  |\n",
      "|1-2 lần       |5625 |26.648888888888887|\n",
      "+--------------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previous_group = (\n",
    "    df.withColumn(\n",
    "        \"previous_group\",\n",
    "        F.when(F.col(\"previous_capped\")==0, \"0 lần\")\n",
    "         .when(F.col(\"previous_capped\")<=2, \"1-2 lần\")\n",
    "         .when(F.col(\"previous_capped\")<=5, \"3-5 lần\")\n",
    "         .otherwise(\"> 5 lần\")\n",
    "    )\n",
    ")\n",
    "\n",
    "previous_agg = (\n",
    "    previous_group.groupBy(\"previous_group\")\n",
    "                  .agg(\n",
    "                      F.count(\"*\").alias(\"total\"),\n",
    "                      (F.avg(\"y_encoded\")*100).alias(\"success_rate\")\n",
    "                  )\n",
    "                  .orderBy(\n",
    "                      F.when(F.col(\"previous_group\")==\"0 lần\", 0)\n",
    "                       .when(F.col(\"previous_group\")==\"1-2 lần\", 1)\n",
    "                       .when(F.col(\"previous_group\")==\"3-5 lần\", 2)\n",
    "                       .otherwise(3)\n",
    "                  )\n",
    ")\n",
    "previous_agg.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**  \n",
    "- Khách hàng **từng được liên hệ 1–2 lần** trước đây có tỷ lệ đồng ý **gấp 3 lần** nhóm chưa từng liên hệ.  \n",
    "- Cho thấy **hiệu ứng ghi nhớ thương hiệu và nhận diện ngân hàng** từ các chiến dịch trước.  \n",
    "\n",
    "**Kết luận:**  \n",
    "- Lịch sử tương tác là một yếu tố mạnh. Cần tận dụng dữ liệu liên hệ trước để xác định nhóm khách hàng tiềm năng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 4: Phân tích biến poutcome (Kết quả chiến dịch trước)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Xác định ảnh hưởng của **kết quả chiến dịch trước (`poutcome`)** đến hành vi trong chiến dịch hiện tại.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   poutcome|count|\n",
      "+-----------+-----+\n",
      "|nonexistent|35563|\n",
      "|    failure| 4252|\n",
      "|    success| 1373|\n",
      "+-----------+-----+\n",
      "\n",
      "+---------------------+-----------+-----+\n",
      "|has_previous_campaign|   poutcome|count|\n",
      "+---------------------+-----------+-----+\n",
      "|                    0|    failure| 4110|\n",
      "|                    0|nonexistent|35563|\n",
      "|                    1|    failure|  142|\n",
      "|                    1|    success| 1373|\n",
      "+---------------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Phân phối poutcome\n",
    "df.groupBy(\"poutcome\").count().orderBy(F.desc(\"count\")).show()\n",
    "\n",
    "# Kiểm tra consistency pdays (has_previous_campaign vs poutcome)\n",
    "df.groupBy(\"has_previous_campaign\",\"poutcome\").count().orderBy(\"has_previous_campaign\",\"poutcome\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kết quả:**  \n",
    "| Kết quả trước (`poutcome`) | Số lượng KH | Tỷ lệ thành công (%) |\n",
    "|-----------------------------|--------------|----------------------|\n",
    "| `success` | 1,373 | **65.1** |\n",
    "| `failure` | 4,252 | **14.2** |\n",
    "| `nonexistent` | 35,563 | **8.8** |\n",
    "\n",
    "**Nhận xét:**  \n",
    "- Nhóm `success` trước đó có xác suất đồng ý rất cao (65%).  \n",
    "- Nhóm `failure` vẫn có khả năng phản hồi tốt hơn khách hàng mới (`nonexistent`).  \n",
    "- Dữ liệu `pdays` và `poutcome` **nhất quán 100%**: không có trường hợp xung đột giữa hai biến.\n",
    "\n",
    "**Kết luận:**  \n",
    "-  Khách hàng từng “thành công” là **lead chất lượng cao nhất** – cần ưu tiên trong chiến dịch mới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 5: Phân tích kết hợp (campaign × poutcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Phân tích mối tương quan giữa **số lần gọi trong chiến dịch hiện tại (`campaign`)** và **kết quả của chiến dịch trước (`poutcome`)** để xem liệu tần suất gọi có tác động khác nhau theo từng nhóm khách hàng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+-----+------------------+\n",
      "|campaign_capped|poutcome   |total|success_rate      |\n",
      "+---------------+-----------+-----+------------------+\n",
      "|1              |failure    |2127 |15.138692994828396|\n",
      "|1              |nonexistent|14791|10.080454330336016|\n",
      "|1              |success    |724  |67.26519337016575 |\n",
      "|2              |failure    |1180 |13.220338983050848|\n",
      "|2              |nonexistent|8990 |8.832035595105674 |\n",
      "|2              |success    |400  |65.25             |\n",
      "|3              |failure    |425  |15.294117647058824|\n",
      "|3              |nonexistent|4772 |8.59178541492037  |\n",
      "|3              |success    |144  |68.75             |\n",
      "|4              |failure    |224  |15.625            |\n",
      "|4              |nonexistent|2379 |7.902480033627575 |\n",
      "|4              |success    |48   |54.166666666666664|\n",
      "|5              |failure    |115  |13.91304347826087 |\n",
      "|5              |nonexistent|1458 |6.5157750342935525|\n",
      "|5              |success    |26   |34.61538461538461 |\n",
      "|6              |failure    |90   |5.555555555555555 |\n",
      "|6              |nonexistent|872  |6.8807339449541285|\n",
      "|6              |success    |17   |58.82352941176471 |\n",
      "|7              |failure    |39   |7.6923076923076925|\n",
      "|7              |nonexistent|581  |5.679862306368331 |\n",
      "|7              |success    |9    |22.22222222222222 |\n",
      "|8              |failure    |27   |3.7037037037037033|\n",
      "|8              |nonexistent|368  |4.3478260869565215|\n",
      "|8              |success    |5    |0.0               |\n",
      "|9              |failure    |10   |0.0               |\n",
      "|9              |nonexistent|273  |6.227106227106227 |\n",
      "|10             |failure    |6    |33.33333333333333 |\n",
      "|10             |nonexistent|219  |4.5662100456621   |\n",
      "|11             |failure    |3    |0.0               |\n",
      "|11             |nonexistent|174  |6.896551724137931 |\n",
      "|12             |failure    |2    |0.0               |\n",
      "|12             |nonexistent|123  |2.4390243902439024|\n",
      "|13             |failure    |2    |0.0               |\n",
      "|13             |nonexistent|90   |4.444444444444445 |\n",
      "|14             |failure    |2    |0.0               |\n",
      "|14             |nonexistent|473  |1.6913319238900635|\n",
      "+---------------+-----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cxp = (\n",
    "    df.groupBy(\"campaign_capped\",\"poutcome\")\n",
    "      .agg(\n",
    "          F.count(\"*\").alias(\"total\"),\n",
    "          (F.avg(\"y_encoded\")*100).alias(\"success_rate\")\n",
    "      )\n",
    "      .orderBy(\"campaign_capped\",\"poutcome\")\n",
    ")\n",
    "cxp.show(100, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kết quả nổi bật:**  \n",
    "- Nhóm **`poutcome = success`** giữ tỷ lệ đồng ý rất cao (≈65–70%) ngay cả khi số lần gọi tăng.  \n",
    "- Nhóm **`failure`** ổn định quanh 13–15%, ít bị ảnh hưởng bởi tần suất gọi.  \n",
    "- Nhóm **`nonexistent`** giảm tỷ lệ đồng ý khi số lần gọi tăng (hiệu ứng mệt mỏi).\n",
    "\n",
    "**Nhận xét:**  \n",
    "- Tần suất gọi **chỉ có tác dụng tích cực** đối với nhóm khách hàng từng thành công.  \n",
    "- Với nhóm chưa từng liên hệ, gọi nhiều lần **không cải thiện** kết quả.\n",
    "\n",
    "**Kết luận:**  \n",
    "- **Chiến dịch nên phân tầng khách hàng theo lịch sử tương tác (`poutcome`)**:  \n",
    "   - Gọi lại thường xuyên hơn với nhóm `success`.  \n",
    "   - Giới hạn số lần liên hệ cho nhóm `nonexistent` để tránh giảm hiệu suất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Tổng kết EDA  \n",
    "\n",
    "| Biến | Insight chính | Hành động khuyến nghị |\n",
    "|-------|----------------|------------------------|\n",
    "| `campaign` | Gọi 1–3 lần cho hiệu quả cao nhất | Giới hạn tối đa 3 cuộc gọi/chiến dịch |\n",
    "| `pdays` | Liên hệ lại trong ≤7 ngày tăng khả năng đồng ý | Ưu tiên follow-up nhanh sau chiến dịch trước |\n",
    "| `previous` | 1–2 lần gọi trước giúp tăng 3× tỷ lệ thành công | Tận dụng nhóm khách hàng từng được liên hệ |\n",
    "| `poutcome` | Nhóm “success” đạt tỷ lệ đồng ý cao nhất (65%) | Tập trung nhóm `poutcome = success` |\n",
    "| `campaign × poutcome` | Hiệu quả tần suất phụ thuộc kết quả trước | Tùy biến tần suất theo từng phân nhóm khách hàng |\n",
    "\n",
    "---\n",
    "**Kết luận chung:**  \n",
    "- Phân tích EDA đã làm rõ mối quan hệ giữa **tần suất gọi, lịch sử liên hệ và kết quả chiến dịch trước**, qua đó giúp xác định nhóm khách hàng tiềm năng và quy trình gọi tối ưu.  \n",
    "- Dữ liệu này là nền tảng quan trọng cho mô hình **Random Forest & GBT** trong các bước tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHẦN 2: Feature Engineering & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Xây dựng mô hình học máy bằng **PySpark MLlib**, nhằm dự đoán khả năng khách hàng đồng ý mở tài khoản gửi tiết kiệm (`y = yes`), dựa trên các biến hành vi liên hệ và kết quả chiến dịch trước.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 1: Kiểm tra tương quan & đa cộng tuyến"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Phát hiện mối tương quan mạnh giữa các biến số, tránh hiện tượng đa cộng tuyến khi huấn luyện mô hình tuyến tính.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr(campaign_capped,pdays) = 0.057559\n",
      "corr(campaign_capped,previous_capped) = -0.090172\n",
      "corr(campaign_capped,has_previous_campaign) = -0.057540\n",
      "corr(campaign_capped,y_encoded) = -0.070182\n",
      "corr(pdays,previous_capped) = -0.571336\n",
      "corr(pdays,has_previous_campaign) = -0.999992\n",
      "corr(pdays,y_encoded) = -0.324914\n",
      "corr(previous_capped,has_previous_campaign) = 0.571332\n",
      "corr(previous_capped,y_encoded) = 0.226429\n",
      "corr(has_previous_campaign,y_encoded) = 0.324877\n"
     ]
    }
   ],
   "source": [
    "# Corr ma trận giữa các biến numeric chính\n",
    "num_cols = [\"campaign_capped\",\"pdays\",\"previous_capped\",\"has_previous_campaign\",\"y_encoded\"]\n",
    "\n",
    "# Spark không có corr matrix built-in cho nhiều cột => tính cặp đôi\n",
    "from itertools import combinations\n",
    "pairs = list(combinations(num_cols, 2))\n",
    "for a,b in pairs:\n",
    "    val = df.stat.corr(a,b)\n",
    "    print(f\"corr({a},{b}) = {val:.6f}\")\n",
    "\n",
    "# Kết luận: nếu |corr| ~ 1 giữa pdays & has_previous_campaign => giữ 1 biến khi dùng mô hình tuyến tính.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kết quả tương quan:**  \n",
    "| Cặp biến | Hệ số tương quan (corr) | Nhận xét |\n",
    "|-----------|--------------------------|-----------|\n",
    "| `pdays` ↔ `has_previous_campaign` | **-0.9999** | Tương quan âm hoàn hảo – 2 biến trùng thông tin. |\n",
    "| `pdays` ↔ `y_encoded` | -0.325 | Khoảng cách liên hệ càng dài, tỷ lệ đồng ý càng thấp. |\n",
    "| `previous_capped` ↔ `y_encoded` | 0.226 | Khách hàng từng được liên hệ nhiều có xu hướng đồng ý cao hơn. |\n",
    "| `campaign_capped` ↔ `y_encoded` | -0.070 | Gọi quá nhiều lần giảm xác suất thành công. |\n",
    "\n",
    "**Nhận xét:**  \n",
    "- `pdays` và `has_previous_campaign` gần như đồng nhất ⇒ chỉ giữ `has_previous_campaign` trong mô hình.  \n",
    "- Các biến khác có tương quan thấp → không gây đa cộng tuyến nghiêm trọng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2: Kiểm tra mất cân bằng lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "| no|36548|\n",
      "|yes| 4640|\n",
      "+---+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|y_encoded|count|\n",
      "+---------+-----+\n",
      "|        1| 4640|\n",
      "|        0|36548|\n",
      "+---------+-----+\n",
      "\n",
      "Yes ratio: 11.3% | No ratio: 88.7%\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"y\").count().show()\n",
    "df.groupBy(\"y_encoded\").count().show()\n",
    "\n",
    "# Tính tỷ lệ yes/no\n",
    "imb = df.agg(F.avg(\"y_encoded\").alias(\"yes_ratio\")).collect()[0][\"yes_ratio\"]\n",
    "print(f\"Yes ratio: {imb*100:.1f}% | No ratio: {(1-imb)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kết quả phân phối nhãn mục tiêu:**  \n",
    "| Nhãn (`y_encoded`) | Số lượng | Tỷ lệ (%) |\n",
    "|--------------------|-----------|-----------|\n",
    "| 0 (no) | 36,548 | **88.7%** |\n",
    "| 1 (yes) | 4,640 | **11.3%** |\n",
    "\n",
    "**Nhận xét:**  \n",
    "- Tập dữ liệu **rất mất cân bằng (≈9:1)**.  \n",
    "- Nếu không xử lý, mô hình sẽ thiên về dự đoán “no”.  \n",
    "- Giải pháp: dùng **trọng số lớp (class_weight)** để tăng ảnh hưởng cho lớp thiểu số."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 3: Chuẩn bị features cho mô hình Spark ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mục tiêu:**  \n",
    "Chuyển đổi và định dạng dữ liệu đã tiền xử lý sang cấu trúc phù hợp với **PySpark MLlib**, phục vụ huấn luyện mô hình trên tập dữ liệu lớn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Các bước thực hiện:**  \n",
    "1. **Mã hóa `poutcome`** → `poutcome_idx` bằng `StringIndexer`.  \n",
    "2. **Chọn 4 đặc trưng chính:**  \n",
    "   `campaign_capped`, `previous_capped`, `has_previous_campaign`, `poutcome_idx`.  \n",
    "3. **Kết hợp đặc trưng** bằng `VectorAssembler` → cột `features`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- y_encoded: integer (nullable = false)\n",
      "\n",
      "+-------------+---------+\n",
      "|features     |y_encoded|\n",
      "+-------------+---------+\n",
      "|(4,[0],[1.0])|0        |\n",
      "|(4,[0],[1.0])|0        |\n",
      "|(4,[0],[1.0])|0        |\n",
      "|(4,[0],[1.0])|0        |\n",
      "|(4,[0],[1.0])|0        |\n",
      "+-------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Encode poutcome -> poutcome_idx (StringIndexer)\n",
    "poutcome_indexer = StringIndexer(inputCol=\"poutcome\", outputCol=\"poutcome_idx\", handleInvalid=\"keep\")\n",
    "\n",
    "# Chọn 4 features như bạn định (loại pdays vì trùng thông tin với has_previous_campaign)\n",
    "feature_cols = [\"campaign_capped\",\"previous_capped\",\"has_previous_campaign\",\"poutcome_idx\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "base_df = Pipeline(stages=[poutcome_indexer, assembler]).fit(df).transform(df).select(\"features\",\"y_encoded\")\n",
    "base_df.printSchema()\n",
    "base_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Dữ liệu hoàn toàn sẵn sàng cho bước train/test split và modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 4: Train/Test split + cân bằng lớp bằng trọng số (không SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chia dữ liệu: **80% train / 20% test**, seed = 42.  \n",
    "- Tính trọng số lớp dựa theo tỷ lệ `no:yes = 8:1`.  \n",
    "- Tạo cột `class_weight` để **cân bằng độ quan trọng** khi tính loss trong mô hình Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = base_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Tính trọng số lớp để cân bằng loss\n",
    "cls = train_df.groupBy(\"y_encoded\").count().collect()\n",
    "counts = {row[\"y_encoded\"]: row[\"count\"] for row in cls}\n",
    "n0, n1 = counts.get(0,1), counts.get(1,1)\n",
    "# weight cho lớp thiểu số cao hơn\n",
    "w0 = 1.0\n",
    "w1 = (n0 / n1)\n",
    "\n",
    "train_df = train_df.withColumn(\n",
    "    \"class_weight\",\n",
    "    F.when(F.col(\"y_encoded\")==1, F.lit(w1)).otherwise(F.lit(w0))\n",
    ")\n",
    "test_df  = test_df.withColumn(\"class_weight\", F.lit(1.0))  # đánh giá công bằng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bước 5: Huấn luyện mô hình Random Forest   (Spark ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cấu hình mô hình:**\n",
    "- `numTrees = 200`, `maxDepth = 12`, `impurity = gini`, `seed = 42`  \n",
    "- Có sử dụng trọng số (`weightCol = class_weight`) để khắc phục mất cân bằng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6557 | Accuracy: 0.8269\n",
      "campaign_capped: 0.0244\n",
      "previous_capped: 0.1653\n",
      "has_previous_campaign: 0.5499\n",
      "poutcome_idx: 0.2604\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"y_encoded\",\n",
    "    weightCol=\"class_weight\",\n",
    "    numTrees=200,\n",
    "    maxDepth=12,\n",
    "    impurity=\"gini\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf_model = rf.fit(train_df)\n",
    "pred = rf_model.transform(test_df)\n",
    "\n",
    "# Đánh giá\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"y_encoded\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"y_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "auc = evaluator_auc.evaluate(pred)\n",
    "acc = evaluator_acc.evaluate(pred)\n",
    "print(f\"AUC: {auc:.4f} | Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "for name, imp in zip(feature_cols, rf_model.featureImportances.toArray()):\n",
    "    print(f\"{name}: {imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance:**\n",
    "| Biến | Importance | Giải thích |\n",
    "|------|-------------|-------------|\n",
    "| `has_previous_campaign` | **0.5499** | Biến mạnh nhất – thể hiện khách hàng từng được liên hệ trước. |\n",
    "| `poutcome_idx` | **0.2604** | Kết quả chiến dịch trước ảnh hưởng lớn đến hành vi hiện tại. |\n",
    "| `previous_capped` | 0.1653 | Số lần liên hệ trong chiến dịch trước giúp tăng khả năng đồng ý. |\n",
    "| `campaign_capped` | 0.0244 | Tần suất gọi hiện tại ảnh hưởng nhẹ. |\n",
    "\n",
    "**Nhận xét:**  \n",
    "- Mô hình RF dự đoán tốt xu hướng khách hàng tiềm năng, nhưng **AUC ~0.65** cho thấy khả năng phân tách lớp vẫn còn hạn chế.  \n",
    "- Kết quả khẳng định lại insight EDA: **“khách hàng từng được liên hệ gần đây có khả năng đồng ý cao nhất.”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 6: Thử nghiệm mô hình GBT (Gradient Boosted Trees)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cấu hình:**  \n",
    "- `maxIter = 150`, `maxDepth = 6`, `stepSize = 0.1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT -> AUC: 0.6552 | Accuracy: 0.9003\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(\n",
    "    featuresCol=\"features\", labelCol=\"y_encoded\",\n",
    "    maxIter=150, maxDepth=6, stepSize=0.1, seed=42\n",
    ")\n",
    "\n",
    "gbt_model = gbt.fit(train_df)\n",
    "pred_gbt = gbt_model.transform(test_df)\n",
    "\n",
    "auc_gbt = evaluator_auc.evaluate(pred_gbt)\n",
    "acc_gbt = evaluator_acc.evaluate(pred_gbt)\n",
    "print(f\"GBT -> AUC: {auc_gbt:.4f} | Accuracy: {acc_gbt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**  \n",
    "- GBT đạt **độ chính xác cao hơn (90%)**, nhưng AUC tương đương RF → vẫn bị ảnh hưởng bởi mất cân bằng lớp.  \n",
    "- GBT học sâu hơn mối quan hệ phi tuyến, nhưng không cải thiện nhiều khả năng phân biệt nhóm “yes”.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Kết luận & Hướng phát triển  \n",
    "\n",
    "| Hạng mục | Kết quả chính | Đề xuất cải thiện |\n",
    "|-----------|----------------|------------------|\n",
    "| Random Forest | AUC = 0.6557, Accuracy = 0.8269 | Tuning tham số, tăng `numTrees`, `maxDepth` |\n",
    "| GBT | AUC = 0.6552, Accuracy = 0.9003 | Cân bằng lớp bằng SMOTE hoặc Weighted GBT |\n",
    "| Feature quan trọng | `has_previous_campaign`, `poutcome_idx` | Duy trì hai biến này trong mọi mô hình |\n",
    "| Dữ liệu mất cân bằng | 11% yes, 89% no | Áp dụng oversampling hoặc focal loss (PyTorch) |\n",
    "\n",
    "---\n",
    "\n",
    "**Tổng kết:**  \n",
    "- Hai mô hình RF và GBT đều cho thấy **tính nhất quán giữa EDA và dự đoán**.  \n",
    "- **`has_previous_campaign`** là yếu tố mạnh nhất → khách hàng từng được liên hệ có khả năng đồng ý cao.  \n",
    "- Kết quả hiện tại là **baseline tốt**, có thể nâng cấp bằng **PyTorch MLP hoặc LightGBM** để cải thiện khả năng phân loại."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
